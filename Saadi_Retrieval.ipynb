{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Saadi-Retrieval.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "You can access our notebook on colab using this link:  \n",
        " [https://colab.research.google.com/drive/1_wO4QH3v81PsLBV6oNBqK9CwxGQ3WOx3?usp=sharing](https://colab.research.google.com/drive/1_wO4QH3v81PsLBV6oNBqK9CwxGQ3WOx3?usp=sharing)"
      ],
      "metadata": {
        "id": "vius4m1TnJqs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "2qA2yh05Uhjp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Qb2Oo-Q1az2B"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cloning git repository related to this project. Crawled data and Crawler code are available in git repository."
      ],
      "metadata": {
        "id": "1KksqF1OVJnF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tandalalam/saadi-retreival.git"
      ],
      "metadata": {
        "id": "46ot2WhlKAmR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11c399cb-8598-4e48-a6e3-c613b605f3ef"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'saadi-retreival'...\n",
            "remote: Enumerating objects: 602, done.\u001b[K\n",
            "remote: Counting objects: 100% (602/602), done.\u001b[K\n",
            "remote: Compressing objects: 100% (594/594), done.\u001b[K\n",
            "remote: Total 602 (delta 27), reused 563 (delta 5), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (602/602), 595.11 KiB | 5.51 MiB/s, done.\n",
            "Resolving deltas: 100% (27/27), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('saadi-retreival')"
      ],
      "metadata": {
        "id": "DbR4Dz8xNNCR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading Boostan from file:"
      ],
      "metadata": {
        "id": "iSEy0gFbXFYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "boostan_data = list()\n",
        "for chapter_name in os.listdir('boostan'):\n",
        "    for file_name in os.listdir(f'boostan/{chapter_name}'):\n",
        "        file = open(f'boostan/{chapter_name}/{file_name}')\n",
        "        poem = file.read()\n",
        "        for hem in [x.strip() for x in poem.split('\\n\\n')]:\n",
        "            if hem:\n",
        "                boostan_data.append([hem, int(chapter_name.split('bab')[1]), int(file_name.split('sh')[1].split('.')[0])])"
      ],
      "metadata": {
        "id": "YfcVz8kccBwO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boostan_data = pd.DataFrame(boostan_data)"
      ],
      "metadata": {
        "id": "hF8rJ9KbbVOw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boostan_data.columns = ['poem', 'chapter', 'section']"
      ],
      "metadata": {
        "id": "5jJKMjQidtwP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boostan_data.sort_values(by=['chapter', 'section'], ignore_index=True, inplace=True)"
      ],
      "metadata": {
        "id": "t1zqWZIkPRiE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boostan_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "zx4Hr7vgPlWl",
        "outputId": "fd9bf036-2e03-436b-ab32-bf5e5d778899"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   poem  chapter  section\n",
              "0      به نام خداوندِ جان‌آفرین\\nحکیمِ سخن‌درزبان‌آفرین        0        1\n",
              "1          خداوند بخشندهٔ دستگیر\\nکریم خطابخش پوزش‌پذیر        0        1\n",
              "2     عزیزی که هر کز درش سر بتافت\\nبه هر در که شد هی...        0        1\n",
              "3       سر پادشاهان گردن‌فراز\\nبه درگاه او بر زمین نیاز        0        1\n",
              "4     نه گردن‌کشان را بگیرد به فور\\nنه عذرآوران را ب...        0        1\n",
              "...                                                 ...      ...      ...\n",
              "4059  به کردار بدشان مقید نکرد\\nبضاعات مزجاتشان رد نکرد       10        4\n",
              "4060  ز لطفت همین چشم داریم نیز\\nبر این بی‌بضاعت ببخ...       10        4\n",
              "4061  کس از من سیه نامه تر دیده نیست\\nکه هیچم فعال پ...       10        4\n",
              "4062  جز این کاعتمادم به یاری تست\\nامیدم به آمرزگاری...       10        4\n",
              "4063    بضاعت نیاوردم الا امید\\nخدایا ز عفوم مکن ناامید       10        4\n",
              "\n",
              "[4064 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e4ddbc5b-d769-45bd-a2f8-994ab9987238\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>poem</th>\n",
              "      <th>chapter</th>\n",
              "      <th>section</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>به نام خداوندِ جان‌آفرین\\nحکیمِ سخن‌درزبان‌آفرین</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>خداوند بخشندهٔ دستگیر\\nکریم خطابخش پوزش‌پذیر</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>عزیزی که هر کز درش سر بتافت\\nبه هر در که شد هی...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>سر پادشاهان گردن‌فراز\\nبه درگاه او بر زمین نیاز</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>نه گردن‌کشان را بگیرد به فور\\nنه عذرآوران را ب...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4059</th>\n",
              "      <td>به کردار بدشان مقید نکرد\\nبضاعات مزجاتشان رد نکرد</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4060</th>\n",
              "      <td>ز لطفت همین چشم داریم نیز\\nبر این بی‌بضاعت ببخ...</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4061</th>\n",
              "      <td>کس از من سیه نامه تر دیده نیست\\nکه هیچم فعال پ...</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4062</th>\n",
              "      <td>جز این کاعتمادم به یاری تست\\nامیدم به آمرزگاری...</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4063</th>\n",
              "      <td>بضاعت نیاوردم الا امید\\nخدایا ز عفوم مکن ناامید</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4064 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e4ddbc5b-d769-45bd-a2f8-994ab9987238')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e4ddbc5b-d769-45bd-a2f8-994ab9987238 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e4ddbc5b-d769-45bd-a2f8-994ab9987238');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading Golestan from file:"
      ],
      "metadata": {
        "id": "KdojXHhW1Qmj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "id": "G9JCsF5jTCK9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will split Golestan's NASR based on their punctiuation:"
      ],
      "metadata": {
        "id": "8EkQ_JHx1VwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "golestan_data = list()\n",
        "for chapter_name in os.listdir('golestan'):\n",
        "    for file_name in os.listdir(f'golestan/{chapter_name}'):\n",
        "        file = open(f'golestan/{chapter_name}/{file_name}')\n",
        "        for hem in [x.strip() for x in re.split('\\n\\n|\\.|\\?|!', file.read())]:\n",
        "            if len(hem.split()) < 3:\n",
        "              continue\n",
        "            if hem:\n",
        "                if file_name.startswith('d'):\n",
        "                    golestan_data.append([hem, 0, 1])\n",
        "                else:\n",
        "                    golestan_data.append([hem, int(chapter_name.split('bab')[1]), int(file_name.split('sh')[1].split('.')[0])])"
      ],
      "metadata": {
        "id": "Zy_CkAgXjCOV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "golestan_data = pd.DataFrame(golestan_data)"
      ],
      "metadata": {
        "id": "MHwpzK2-ploS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "golestan_data.columns = ['poem', 'chapter', 'section']"
      ],
      "metadata": {
        "id": "5InLM2R3ppTo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "golestan_data.sort_values(by=['chapter', 'section'], ignore_index=True, inplace=True)"
      ],
      "metadata": {
        "id": "B-9lU_XcWnBl"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "golestan_data"
      ],
      "metadata": {
        "id": "C6E2xOzepvSf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "d9e10892-024a-4b7f-8e92-d4f8c0686c5f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   poem  chapter  section\n",
              "0                         بِسم اللهِ الرَّحمنِ الرَّحیم        0        1\n",
              "1     منّت خدای را عز و جل که طاعتش موجب قربت است و ...        0        1\n",
              "2     هر نفسی که فرو می رود ممدّ حیات است و چون بر م...        0        1\n",
              "3     پس در هر نفسی دو نعمت موجود است و بر هر نعمتی ...        0        1\n",
              "4      از دست و زبان که بر آید\\nکز عهدهٔ شکرش به در آید        0        1\n",
              "...                                                 ...      ...      ...\n",
              "2497  غالب گفتار سعدی طرب انگیز است و طیبت آمیز و کو...        8      109\n",
              "2498  ما نصیحت به جای خود کردیم\\nروزگاری در این به س...        8      109\n",
              "2499  گر نیاید به گوش رغبت کس\\nبر رسولان پیام باشد و بس        8      109\n",
              "2500  یا ناظراً فیه سَل باللهِ مرحمةً\\nعلی المصنفِ و...        8      109\n",
              "2501  و اَطلُب لِنَفسِکَ مِن خیرٍ تُریدُ بها\\nمِن بع...        8      109\n",
              "\n",
              "[2502 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bd002cbd-3844-4491-ad6e-ed00c13a7a60\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>poem</th>\n",
              "      <th>chapter</th>\n",
              "      <th>section</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>بِسم اللهِ الرَّحمنِ الرَّحیم</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>منّت خدای را عز و جل که طاعتش موجب قربت است و ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>هر نفسی که فرو می رود ممدّ حیات است و چون بر م...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>پس در هر نفسی دو نعمت موجود است و بر هر نعمتی ...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>از دست و زبان که بر آید\\nکز عهدهٔ شکرش به در آید</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2497</th>\n",
              "      <td>غالب گفتار سعدی طرب انگیز است و طیبت آمیز و کو...</td>\n",
              "      <td>8</td>\n",
              "      <td>109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2498</th>\n",
              "      <td>ما نصیحت به جای خود کردیم\\nروزگاری در این به س...</td>\n",
              "      <td>8</td>\n",
              "      <td>109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2499</th>\n",
              "      <td>گر نیاید به گوش رغبت کس\\nبر رسولان پیام باشد و بس</td>\n",
              "      <td>8</td>\n",
              "      <td>109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2500</th>\n",
              "      <td>یا ناظراً فیه سَل باللهِ مرحمةً\\nعلی المصنفِ و...</td>\n",
              "      <td>8</td>\n",
              "      <td>109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2501</th>\n",
              "      <td>و اَطلُب لِنَفسِکَ مِن خیرٍ تُریدُ بها\\nمِن بع...</td>\n",
              "      <td>8</td>\n",
              "      <td>109</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2502 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd002cbd-3844-4491-ad6e-ed00c13a7a60')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bd002cbd-3844-4491-ad6e-ed00c13a7a60 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bd002cbd-3844-4491-ad6e-ed00c13a7a60');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Concatanating data from Boostan and Golestan:"
      ],
      "metadata": {
        "id": "zKlZlPrP1m0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = pd.concat([boostan_data, golestan_data], ignore_index=True)['poem']"
      ],
      "metadata": {
        "id": "BRaESnYp94qW"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install hazm"
      ],
      "metadata": {
        "id": "tcp9Gdxah_Ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b4e7556-1a22-4d9a-a1c4-9a7be4cde3ca"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hazm\n",
            "  Downloading hazm-0.7.0-py3-none-any.whl (316 kB)\n",
            "\u001b[K     |████████████████████████████████| 316 kB 7.2 MB/s \n",
            "\u001b[?25hCollecting nltk==3.3\n",
            "  Downloading nltk-3.3.0.zip (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 15.2 MB/s \n",
            "\u001b[?25hCollecting libwapiti>=0.2.1\n",
            "  Downloading libwapiti-0.2.1.tar.gz (233 kB)\n",
            "\u001b[K     |████████████████████████████████| 233 kB 44.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm) (1.15.0)\n",
            "Building wheels for collected packages: nltk, libwapiti\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.3-py3-none-any.whl size=1394487 sha256=07713a8ef8adabd12619adf791a00ea5657238eb2dbfd36b602d3a7c42231651\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/fd/0c/d92302c876e5de87ebd7fc0979d82edb93e2d8d768bf71fac4\n",
            "  Building wheel for libwapiti (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for libwapiti: filename=libwapiti-0.2.1-cp37-cp37m-linux_x86_64.whl size=153966 sha256=3b686fdca98631391cb38fb3aad3f436e0022c2a76358ccf492eecc2d35f057f\n",
            "  Stored in directory: /root/.cache/pip/wheels/ab/b2/5b/0fe4b8f5c0e65341e8ea7bb3f4a6ebabfe8b1ac31322392dbf\n",
            "Successfully built nltk libwapiti\n",
            "Installing collected packages: nltk, libwapiti, hazm\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.7\n",
            "    Uninstalling nltk-3.7:\n",
            "      Successfully uninstalled nltk-3.7\n",
            "Successfully installed hazm-0.7.0 libwapiti-0.2.1 nltk-3.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import unicode_literals\n",
        "from hazm import *\n",
        "import tqdm\n",
        "import string"
      ],
      "metadata": {
        "id": "pzfW1fHa9y0p"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing stopwords and words that should be replaced:  \n",
        "We have use stop-words for persian poems from [here](https://github.com/amnghd/Persian_poems_corpus). And word that should replaced are written by ourselves."
      ],
      "metadata": {
        "id": "K7KcBBizXqQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = ['زن']\n",
        "replace_dict = {}\n",
        "punctuations = '\\.:!،؛؟»\\]\\)\\}«\\[\\(\\{' + string.punctuation\n",
        "\n",
        "with open('stopwords.txt') as f:\n",
        "    var = f.readline()\n",
        "    while var:\n",
        "        stopwords.append(var.strip())\n",
        "        var = f.readline()\n",
        "\n",
        "with open('replace.txt') as f:\n",
        "    line = f.readline()\n",
        "    while line:\n",
        "        key, value = line.split('-')\n",
        "        key, value = key.strip(), value.strip()\n",
        "        replace_dict[f'{key}'] = f'{value}'\n",
        "        line = f.readline()"
      ],
      "metadata": {
        "id": "mkjR59seKOV4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing Data"
      ],
      "metadata": {
        "id": "pL5pSO5DVebz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalizer = Normalizer()\n",
        "stemmer = Stemmer()\n",
        "lemmatizer = Lemmatizer()\n",
        "\n",
        "def replace_function(string):\n",
        "    if string in replace_dict:\n",
        "      return replace_dict[string]\n",
        "    return string\n",
        "\n",
        "def sent_pre_process(sentence, normalize=True, remove_stopwords=False, stemme=False, lemmatize=True, replace=True, remove_punctuations=True, is_first=True):\n",
        "\n",
        "    # replace some charachters\n",
        "    replace_char = {'هٔ': 'ه',\n",
        "                    'ۀ' : 'ه',\n",
        "                    'ه‌ی' : 'ه'}\n",
        "    \n",
        "    if remove_punctuations:\n",
        "      for char in punctuations:\n",
        "        replace_char[char] = \" \"\n",
        "\n",
        "    for key, value in replace_char.items():\n",
        "        sentence = sentence.replace(key, value)\n",
        "\n",
        "    if normalize:\n",
        "        sentence = normalizer.normalize(sentence)\n",
        "    if stemme:\n",
        "        sentence = stemmer.stemme(sentence)\n",
        "    if lemmatize:\n",
        "        sentence = lemmatizer.lemmatize(sentence)\n",
        "    \n",
        "\n",
        "    tokens = word_tokenize(sentence)\n",
        "    \n",
        "    if replace:\n",
        "        tokens = [replace_function(token) for token in tokens]\n",
        "    if remove_stopwords:\n",
        "        tokens = [token for token in tokens if token not in stopwords]\n",
        "    \n",
        "    if is_first:\n",
        "        return sent_pre_process(\" \".join(tokens), normalize, remove_stopwords, stemme, lemmatize, replace, remove_punctuations, False)\n",
        "    \n",
        "    return tokens\n",
        "\n",
        "def pre_process(sentences, normalize=True, remove_stopwords=False, stemme=False, lemmatize=True, replace=True, remove_punctuations=True, is_first=True, MIN_COUNT=3, put_index=False):\n",
        "    if put_index:\n",
        "        processed = [(sent_pre_process(sent, normalize, remove_stopwords, stemme, lemmatize, replace, remove_punctuations, is_first), i) for i, sent in enumerate(sentences)]\n",
        "        return [t for t in processed if len(list(t[0])) > MIN_COUNT]\n",
        "    processed = [sent_pre_process(sent, normalize, remove_stopwords, stemme, lemmatize, replace, remove_punctuations, is_first) for sent in sentences]\n",
        "    return [t for t in processed if len(list(t)) > MIN_COUNT]"
      ],
      "metadata": {
        "id": "3JFys7VThw9_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Boolean Retreival"
      ],
      "metadata": {
        "id": "2rC_sfQfV81R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For convinience, we use CountVectorizer and then convert its values from number to boolean to get boolean retreival matrix:"
      ],
      "metadata": {
        "id": "LxiAh9v2X8ij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "tf = CountVectorizer(analyzer= lambda x: sent_pre_process(x, remove_stopwords=True))\n",
        "tf_data = tf.fit_transform(all_data)\n",
        "tf_data = tf_data.toarray().astype(bool)"
      ],
      "metadata": {
        "id": "2joRrt84mIRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.transform(['ما ز یاران چشم یاری']).toarray()"
      ],
      "metadata": {
        "id": "SvmFym5FmJHZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1816931-3f8e-48db-82d2-a2800fe03fc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf_data"
      ],
      "metadata": {
        "id": "sv8xqQlRmLYj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f7c3f88-cd38-4360-e431-f92763fe7354"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       ...,\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False],\n",
              "       [False, False, False, ..., False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def boolean_retrieval(str, k=10):\n",
        "  query_vec = tf.transform([str]).toarray()[0]\n",
        "  scores = np.dot(tf_data, query_vec)\n",
        "  args = np.argsort(scores)[::-1]\n",
        "  k_args = args[:k]\n",
        "  return np.concatenate([[scores[k_args]], [all_data[k_args]]]).T"
      ],
      "metadata": {
        "id": "Qeft12KdmN1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "boolean_retrieval('به نام خداوند جان و خرد کز این برتر اندیشه بر نگذرد')"
      ],
      "metadata": {
        "id": "XeCnl1PkmPzb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04fd13db-6de8-43c6-871b-5df7d04b578d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2, 'اگر باد سرد نفس نگذرد\\nتف معده جان در خروش آورد'],\n",
              "       [1,\n",
              "        'به نام خداوندِ جان\\u200cآفرین\\nحکیمِ سخن\\u200cدرزبان\\u200cآفرین'],\n",
              "       [1,\n",
              "        'در این کشور اندیشه کردم بسی\\nپریشان\\u200cتر از خود ندیدم کسی'],\n",
              "       [1, 'عجب آن که غراب از مجاورت طوطی هم به جان آمده بود و ملول شده'],\n",
              "       [1, 'هر آن کس که جور بزرگان نبرد\\nنسوزد دلش بر ضعیفان خرد'],\n",
              "       [1,\n",
              "        'که درمانده\\u200cام دست گیر ای صنم\\nبه جان آمدم رحم کن بر تنم'],\n",
              "       [1,\n",
              "        'یکی را زنی صاحب جمال جوان درگذشت و مادرزن فرتوت به علت کابین در خانه متمکن بماند و مرد از محاورت او به جان رنجیدی و از مجاورت او چاره ندیدی تا گروهی آشنایان به پرسیدن آمدندش'],\n",
              "       [1,\n",
              "        'چو الب ارسلان جان به جان\\u200cبخش داد\\nپسر تاج شاهی به سر برنهاد'],\n",
              "       [1, 'ز دوران ملک پدر یاد کن\\nدل از بند اندیشه آزاد کن'],\n",
              "       [1, 'وگر راست گفت ای خداوند پاک\\nمرا توبه ده تا نگردم هلاک']],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can train a retreival system that returns the whole related poem (file) instead of only one MESRAA or BEIT just as easily:"
      ],
      "metadata": {
        "id": "T1Wklg9F73Tl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setting book column for both golestan and boostan:\n",
        "golestan_data['book'] = 'Golestan'\n",
        "boostan_data['book'] = 'Boostan'"
      ],
      "metadata": {
        "id": "oEmOC-V68MVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([boostan_data, golestan_data], ignore_index=True)\n",
        "all_data = df['poem']\n",
        "file_based_df = df.groupby(['book', 'chapter', 'section']).apply(lambda f: ' '.join(f['poem'].tolist())).reset_index()\n",
        "file_based_df.columns = ['book', 'chapter', 'section', 'poem']\n",
        "file_based_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJGpgQwU8e1-",
        "outputId": "638256fa-2e44-42c6-a185-25d0e1cdf4ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      book  chapter  section  \\\n",
              "0  Boostan        0        1   \n",
              "1  Boostan        0        2   \n",
              "2  Boostan        0        3   \n",
              "3  Boostan        0        4   \n",
              "4  Boostan        0        5   \n",
              "\n",
              "                                                poem  \n",
              "0  به نام خداوندِ جان‌آفرین\\nحکیمِ سخن‌درزبان‌آفر...  \n",
              "1  کریم السجایا جمیل الشیم\\nنبی البرایا شفیع الام...  \n",
              "2  در اقصای عالم بگشتم بسی\\nبه سر بردم ایام با هر...  \n",
              "3  مرا طبع از این نوع خواهان نبود\\nسر مدحت پادشاه...  \n",
              "4  اتابک محمد شه نیکبخت\\nخداوند تاج و خداوند تخت ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5b4d40a3-e2a0-4b1c-8c77-170ca7f99cb7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>book</th>\n",
              "      <th>chapter</th>\n",
              "      <th>section</th>\n",
              "      <th>poem</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Boostan</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>به نام خداوندِ جان‌آفرین\\nحکیمِ سخن‌درزبان‌آفر...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Boostan</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>کریم السجایا جمیل الشیم\\nنبی البرایا شفیع الام...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Boostan</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>در اقصای عالم بگشتم بسی\\nبه سر بردم ایام با هر...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Boostan</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>مرا طبع از این نوع خواهان نبود\\nسر مدحت پادشاه...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Boostan</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>اتابک محمد شه نیکبخت\\nخداوند تاج و خداوند تخت ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b4d40a3-e2a0-4b1c-8c77-170ca7f99cb7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5b4d40a3-e2a0-4b1c-8c77-170ca7f99cb7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5b4d40a3-e2a0-4b1c-8c77-170ca7f99cb7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_base_tf = CountVectorizer(analyzer= lambda x: sent_pre_process(x, remove_stopwords=True))\n",
        "file_base_tf_data = file_base_tf.fit_transform(file_based_df.poem)\n",
        "file_base_tf_data = file_base_tf_data.toarray().astype(bool)\n",
        "\n",
        "def file_base_boolean_retrieval(str, k=10):\n",
        "  query_vec = file_base_tf.transform([str]).toarray()[0]\n",
        "  scores = np.dot(file_base_tf_data, query_vec)\n",
        "  args = np.argsort(scores)[::-1]\n",
        "  k_args = args[:k]\n",
        "  return np.concatenate([[scores[k_args]], [file_based_df.poem[k_args]]]).T"
      ],
      "metadata": {
        "id": "PH6UYEfcAQse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_base_boolean_retrieval('به نام خداوند جان و خرد کز این برتر اندیشه بر نگذرد', k=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTOE7XzyBj_o",
        "outputId": "b5390add-e722-400e-bb19-ac0a44932711"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4,\n",
              "        'بِسم اللهِ الرَّحمنِ الرَّحیم منّت خدای را عز و جل که طاعتش موجب قربت است و به شکر اندرش مزید نعمت هر نفسی که فرو می رود ممدّ حیات است و چون بر می آید مفرّح ذات پس در هر نفسی دو نعمت موجود است و بر هر نعمتی شکری واجب از دست و زبان که بر آید\\nکز عهدهٔ شکرش به در آید اِعملوا آلَ داودَ شکراً وَ قلیلٌ مِن عبادیَ الشکور بنده همان به که ز تقصیر خویش\\nعذر به درگاه خدای آورد ور نه سزاوار خداوندیش\\nکس نتواند که به جای آورد باران رحمت بی حسابش همه را رسیده و خوان نعمت بی دریغش همه جا کشیده پردهٔ ناموس بندگان به گناه فاحش ندرد و وظیفهٔ روزی به خطای منکر نبرد ای کریمی که از خزانهٔ غیب\\nگبر و ترسا وظیفه خور داری دوستان را کجا کنی محروم\\nتو که با دشمن این نظر داری فرّاش باد صبا را گفته تا فرش زمرّدی بگسترد و دایهٔ ابر بهاری را فرموده تا بنات نبات در مهد زمین بپرورد درختان را به خلعت نوروزی قبای سبز ورق در بر گرفته و اطفال شاخ را به قدوم موسم ربیع کلاه شکوفه بر سر نهاده عصاره نالی به قدرت او شهد فایق شده و تخم خرمایی به تربیتش نخل باسق گشته ابر و باد و مه و خورشید و فلک در کارند\\nتا تو نانی به کف آریّ و به غفلت نخوری همه از بهر تو سرگشته و فرمانبردار\\nشرط انصاف نباشد که تو فرمان نبری در خبر است از سرور کاینات و مفخر موجودات و رحمت عالمیان و صفوت آدمیان و تتمهٔ دور زمان محمد مصطفی صلی الله علیه و سلم، شفیعٌ مطاعٌ نبیٌ کریم\\nقسیمٌ جسیمٌ نسیمٌ وسیم چه غم دیوار امّت را که دارد چون تو پشتیبان\\nچه باک از موج بحر آن را که باشد نوح کشتیبان بلغَ العلی بِکمالِه کشفَ الدُّجی بِجَمالِه\\nحَسنتْ جَمیعُ خِصالِه صلّوا علیه و آله هر گاه که یکی از بندگان گنهکار پریشان روزگار دست انابت به امید اجابت به درگاه حق جل و علا بردارد ایزد تعالی در وی نظر نکند بازش بخواند باز اعراض کند بازش به تضرّع و زاری بخواند حق سبحانه و تعالی فرماید یا ملائکتی قَد استَحْیَیتُ مِن عبدی و لَیس لَهُ غیری فَقد غَفَرت لَهُ دعوتش را اجابت کردم و حاجتش بر آوردم که از بسیاری دعا و زاری بنده همی شرم دارم کرم بین و لطف خداوندگار\\nگنه بنده کرده است و او شرمسار عاکفان کعبهٔ جلالش به تقصیر عبادت معترف که ما عبدناکَ حقّ عبادتِک و واصفان حلیهٔ جمالش به تحیر منسوب که ما عَرَفناکَ حقّ مَعرِفتِک گر کسی وصف او ز من پرسد\\nبیدل از بی نشان چه گوید باز عاشقان کشتگان معشوقند\\nبر نیاید ز کشتگان آواز یکی از صاحبدلان سر به جیب مراقبت فرو برده بود و در بحر مکاشفت مستغرق شده حالی که از این معامله باز آمد یکی از دوستان گفت: از این بستان که بودی ما را چه تحفه کرامت کردی؟ گفت: به خاطر داشتم که چون به درخت گل رسم دامنی پر کنم هدیه اصحاب را، چون برسیدم بوی گلم چنان مست کرد که دامنم از دست برفت ای مرغ سحر عشق ز پروانه بیاموز\\nکآن سوخته را جان شد و آواز نیامد این مدعیان در طلبش بی خبرانند\\nکآن را که خبر شد خبری باز نیامد ای برتر از خیال و قیاس و گمان و وهم\\nوز هر چه گفته\\u200cاند و شنیدیم و خوانده\\u200cایم مجلس تمام گشت و به آخر رسید عمر\\nما همچنان در اوّل وصف تو مانده\\u200cایم ذکر جمیل سعدی که در افواه عوام افتاده است و صیت سخنش که در بسیط زمین رفته و قصب الجیب حدیثش که همچون شکر می\\u200cخورند و رقعهٔ منشآتش که چون کاغذ زر می\\u200cبرند بر کمال فضل و بلاغت او حمل نتوان کرد بلکه خداوند جهان و قطب دایرهٔ زمان و قایم مقام سلیمان و ناصر اهل ایمان اتابک اعظم مظفر الدنیا و الدین ابوبکر بن سعد بن زنگی ظلّ الله تعالی فی ارضه رَبِّ اِرْضَ عَنهُ و اَرْضِه به عین عنایت نظر کرده است و تحسین بلیغ فرموده و ارادت صادق نموده، لاجرم کافهٔ انام از خواص و عوام به محبت او گراییده\\u200cاند که الناسُ علی دینِ ملوکِهم زآن گه که تو را بر من مسکین نظر است\\nآثارم از آفتاب مشهور تر است گر خود همه عیبها بدین بنده در است\\nهر عیب که سلطان بپسندد هنر است گِلی خوشبوی در حمام روزی\\nرسید از دست محبوبی به دستم بدو گفتم که مشکی یا عبیری\\nکه از بوی دلاویز تو مستم بگفتا من گلی ناچیز بودم\\nو لیکن مدّتی با گل نشستم کمال همنشین در من اثر کرد\\nوگرنه من همان خاکم که هستم اللّهمَ مَتِّع المسلمینَ بطولِ حیاتِه و ضاعِف جمیلَ حسناتِه و ارْفَع درجةَ اودّائه و وُلاتِه وَ دمِّر علی اعدائه و شُناتِه بماتُلِیَ فی القرآن مِنْ آیاتِهِ اللّهُم آمِن بَلدَه و احفَظْ وَلَدَه لَقد سَعِدَ الدُنیا بهِ دامَ سعدُه\\nوَ ایَّدَه المولی بِاَلویةِ النَّصرِ کذلکَ ینشألینةُ هو عِرقُها\\nو حُسنُ نباتِ الارضِ من کرمِ البذرِ ایزد تعالی و تقدس خطهٔ پاک شیراز را به هیبت حاکمان عادل و همت عالمان عامل تا زمان قیامت در امان سلامت نگه داراد اقلیم پارس را غم از آسیب دهر نیست\\nتا بر سرش بود چو تویی سایه خدا امروز کس نشان ندهد در بسیط خاک\\nمانند آستان درت مأمن رضا بر توست پاس خاطر بیچارگان و شکر\\nبر ما و بر خدای جهان آفرین جزا یا رب ز باد فتنه نگهدار خاک پارس\\nچندان که خاک را بود و باد را بقا یک شب تأمل ایام گذشته می\\u200cکردم و بر عمر تلف کرده تأسف می\\u200cخوردم و سنگ سراچهٔ دل به الماس آب دیده می\\u200cسفتم و این بیت\\u200cها مناسب حال خود می\\u200cگفتم: هر دم از عمر می رود نفسی\\nچون نگه می\\u200cکنم نمانده بسی ای که پنجاه رفت و در خوابی\\nمگر این پنج روز دریابی خجل آن کس که رفت و کار نساخت\\nکوس رحلت زدند و بار نساخت خواب نوشین بامداد رحیل\\nباز دارد پیاده را ز سبیل هر که آمد عمارتی نو ساخت\\nرفت و منزل به دیگری پرداخت وآن دگر پخت همچنین هوسی\\nوین عمارت بسر نبرد کسی یار ناپایدار دوست مدار\\nدوستی را نشاید این غدّار نیک و بد چون همی بباید مرد\\nخنک آن کس که گوی نیکی برد برگ عیشی به گور خویش فرست\\nکس نیارد ز پس ز پیش فرست عمر برف است و آفتاب تموز\\nاندکی ماند و خواجه غرّه هنوز ای تهی دست رفته در بازار\\nترسمت پر نیاوری دستار هر که مزروع خود بخورد به خوید\\nوقت خرمنش خوشه باید چید بعد از تأمل این معنی مصلحت چنان دیدم که در نشیمن عزلت نشینم و دامن صحبت فراهم چینم و دفتر از گفت\\u200cهای پریشان بشویم و من بعد پریشان نگویم زبان بریده به کنجی نشسته صمٌّ بکمٌ\\nبه از کسی که نباشد زبانش اندر حکم تا یکی از دوستان که در کجاوه انیس من بود و در حجره جلیس، به رسم قدیم از در در آمد چندان که نشاط ملاعبت کرد و بساط مداعبت گسترد جوابش نگفتم و سر از زانوی تعبّد بر نگرفتم رنجیده نگه کرد و گفت: کنونت که امکان گفتار هست\\nبگو ای برادر به لطف و خوشی که فردا چو پیک اجل در رسید\\nبه حکم ضرورت زبان در کشی کسی از متعلقان منش بر حسب واقعه مطلع گردانید که فلان عزم کرده است و نیت جزم که بقیت عمر معتکف نشیند و خاموشی گزیند، تو نیز اگر توانی سر خویش گیر و راه مجانبت پیش گفتا: به عزت عظیم و صحبت قدیم که دم بر نیارم و قدم بر ندارم مگر آن گه که سخن گفته شود به عادت مألوف و طریق معروف که آزردن دوستان جهل است و کفّارت یمین سهل و خلاف راه صواب است و نقص رای اولوالالباب ذوالفقار علی در نیام و زبان سعدی در کام زبان در دهان ای خردمند چیست\\nکلید در گنج صاحب هنر چو در بسته باشد چه داند کسی\\nکه جوهر فروش است یا پیله ور اگر چه پیش خردمند خامشی ادب است\\nبه وقت مصلحت آن به که در سخن کوشی دو چیز طیرهٔ عقل است دم فرو بستن\\nبه وقت گفتن و گفتن به وقت خاموشی فی الجمله زبان از مکالمهٔ او در کشیدن قوّت نداشتم و روی از محاورهٔ او گردانیدن مروّت ندانستم که یار موافق بود و ارادت صادق چو جنگ آوری با کسی برستیز\\nکه از وی گزیرت بود یا گریز به حکم ضرورت سخن گفتم و تفرج کنان بیرون رفتیم در فصل ربیع که صولت برد آرمیده بود و ایام دولت ورد رسیده پیراهن برگ بر درختان\\nچون جامهٔ عید نیکبختان اول اردیبهشت ماه جلالی\\nبلبل گوینده بر منابر قضبان بر گل سرخ از نم اوفتاده لآلی\\nهمچو عرق بر عذار شاهد غضبان شب را به بوستان با یکی از دوستان اتفاق مبیت افتاد، موضعی خوش و خرّم و درختان در هم گفتی که خردهٔ مینا بر خاکش ریخته و عقد ثریا از تارکش آویخته روضةٌ ماءُ نهرِها سَلسال\\nدوحةٌ سَجعُ طیرِها موزون آن پر از لالهای رنگارنگ\\nوین پر از میوه\\u200cهای گوناگون باد در سایهٔ درختانش\\nگسترانیده فرش بوقلمون بامدادان که خاطر باز آمدن بر رای نشستن غالب آمد دیدمش دامنی گل و ریحان و سنبل و ضیمران فراهم آورده و رغبت شهر کرده گفتم: گل بستان را چنان که دانی بقایی و عهد گلستان را وفایی نباشد و حکما گفته\\u200cاند هر چه نپاید دلبستگی را نشاید گفتا: طریق چیست؟ گفتم: برای نزهت ناظران و فسحت حاضران کتاب گلستان توانم تصنیف کردن که باد خزان را بر ورق او دست تطاول نباشد و گردش زمان عیش ربیعش را به طیش خریف مبدل نکند به چه کار آیدت ز گل طبقی\\nاز گلستان من ببر ورقی گل همین پنج روز و شش باشد\\nوین گلستان همیشه خوش باشد حالی که من این بگفتم دامن گل بریخت و در دامنم آویخت که الکریم اذا وعدَ وفا فصلی در همان روز اتفاق بیاض افتاد در حسن معاشرت و آداب محاورت در لباسی که متکلمان را به کار آید و مترسّلان را بلاغت بیفزاید فی الجمله هنوز از گل بستان بقیّتی موجود بود که کتاب گلستان تمام شد و تمام آنگه شود به حقیقت که پسندیده آید در بارگاه شاه جهان پناه سایهٔ کردگار و پرتو لطف پروردگار ذخر زمان و کهف امان المؤیدُ من السماء المنصورُ علی الاعداء عضدُ الدولةِ القاهرةِ سراجُ الملةِ الباهرةِ جمالُ الانامِ مفخرُ الاسلام سعدُ بن الاتابکِ الاعظم شاهنشاه المعظم مولی ملوک العرب و العجم سلطان البر و البحر وارث ملک سلیمان مظفرالدین ابی بکر بن سعد بن زنگی ادام الله اقبالَهما و ضاعَفَ جَلالَهما وَ جعَل الی کلِّ خیر مآلهما و به کرشمه لطف خداوندی مطالعه فرماید گر التفات خداوندیش بیاراید\\nنگارخانه چینی و نقش ارتنگیست امید هست که روی ملال در نکشد\\nاز این سخن که گلستان نه جای دلتنگیست علی الخصوص که دیباچهٔ همایونش\\nبه نام سعد ابوبکر سعد بن زنگیست دیگر عروس فکر من از بی جمالی سر بر نیارد و دیدهٔ یأس از پشت پای خجالت بر ندارد و در زمرهٔ صاحبدلان متجلی نشود مگر آن گه که متحلّی گردد به زیور قبول امیر کبیر عالم عادل مؤید مظفر منصور ظهیر سریر سلطنت و مشیر تدبیر مملکت کهف الفقرا ملاذُ الغربا مربّی الفضلا محبُّ الاتقیا افتخار آل فارس یمینُ الملک ملک الخواص فخر الدولة والدین غیاث الاسلام و المسلمین عمدةُ الملوکِ و السلاطین ابوبکر بنُ ابی نصر اطال الله عمرَه و اجل قدرَه و شرَح صدرَه و ضاعَف اجرَه که ممدوح اکابر آفاق است و مجموع مکارم اخلاق هر که در سایهٔ عنایت اوست\\nگنهش طاعت است و دشمن دوست به هر یک از سایر بندگان حواشی خدمتی متعین است که اگر در ادای برخی از آن تهاون و تکاسل روا دارند در معرض خطاب آیند و در محل عتاب مگر بر این طایفهٔ درویشان که شکر نعمت بزرگان واجب است و ذکر جمیل و دعای خیر و اداء چنین خدمتی در غیبت اولیتر است که در حضور، که آن به تصنع نزدیک است و این از تکلف دور پشت دوتای فلک راست شد از خرّمی\\nتا چو تو فرزند زاد مادر ایام را حکمت محض است اگر لطف جهان آفرین\\nخاص کند بنده\\u200cای مصلحت عام را دولت جاوید یافت هر که نکونام زیست\\nکز عقبش ذکر خیر زنده کند نام را وصف تو را گر کنند ور نکنند اهل فضل\\nحاجت مشّاطه نیست روی دلارام را تقصیر و تقاعدی که در مواظبت خدمت بارگاه خداوندی می\\u200cرود بنا بر آن است که طایفه\\u200cای از حکماء هندوستان در فضایل بزرجمهر سخن می\\u200cگفتند، به آخر جز این عیبش ندانستند که در سخن گفتن بطیء است یعنی درنگ بسیار می\\u200cکند و مستمع را بسی منتظر باید بودن تا تقریر سخنی کند بزرجمهر بشنید و گفت: اندیشه کردن که چه گویم به از پشیمانی خوردن که چرا گفتم سخندان پرورده پیر کهن\\nبیندیشد آن گه بگوید سخن مزن تا توانی به گفتار دم\\nنکو گوی گر دیر گویی چه غم بیندیش وآن گه بر آور نفس\\nو زآن پیش بس کن که گویند بس به نطق آدمی بهتر است از دواب\\nدواب از تو به گر نگویی صواب فکیف در نظر اعیان حضرت خداوندی عزّ نصرُه که مجمع اهل دل است و مرکز علمای متبحر اگر در سیاقت سخن دلیری کنم شوخی کرده باشم و بضاعت مزجاة به حضرت عزیز آورده و شبه در جوهریان جوی نیارد و چراغ پیش آفتاب پرتوی ندارد و مناره بلند بر دامن کوه الوند پست نماید هر که گردن به دعوی افرازد\\nخویشتن را به گردن اندازد سعدی افتاده\\u200cایست آزاده\\nکس نیاید به جنگ افتاده اول اندیشه وآنگهی گفتار\\nپای بست آمده\\u200cست و پس دیوار نخلبندی دانم ولی نه در بستان و شاهدی فروشم ولیکن نه در کنعان لقمان را گفتند: حکمت از که آموختی؟ گفت: از نابینایان که تا جای نبینند پای ننهند قدّم الخروجَ قبلَ الولوجُ، مردیت بیازمای وآنگه زن کن گر چه شاطر بود خروس به جنگ\\nچه زند پیش باز رویین چنگ گربه شیر است در گرفتن موش\\nلیک موش است در مصاف پلنگ اما به اعتماد سعت اخلاق بزرگان که چشم از عوایب زیردستان بپوشند و در افشای جرائم کهتران نکوشند کلمه\\u200cای چند به طریق اختصار از نوادر و امثال و شعر و حکایات و سیر ملوک ماضی رحمهم الله در این کتاب درج کردیم و برخی از عمر گرانمایه بر او خرج، موجب تصنیف کتاب این بود و بالله التوفیق بماند سالها این نظم و ترتیب\\nز ما هر ذرّه خاک افتاده جایی غرض نقشیست کز ما باز ماند\\nکه هستی را نمی بینم بقایی مگر صاحبدلی روزی به رحمت\\nکند در کار درویشان دعایی امعان نظر در ترتیب کتاب و تهذیب ابواب ایجاز سخن مصلحت دید تا بر این روضهٔ غنا و حدیقهٔ غلبا چون بهشت هشت باب اتفاق افتاد از آن مختصر آمد تا به ملال نیانجامد باب اوّل: در سیرت پادشاهان باب دوم: در اخلاق درویشان باب سوم: در فضیلت قناعت باب چهارم: در فواید خاموشی باب پنجم: در عشق و جوانی باب ششم: در ضعف و پیری باب هفتم: در تأثیر تربیت باب هشتم: در آداب صحبت در این مدت که ما را وقت خوش بود\\nز هجرت ششصد و پنجاه و شش بود مراد ما نصیحت بود و گفتیم\\nحوالت با خدا کردیم و رفتیم']],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we can use this to create our file-based retreival system for all our models. But in this notebook, our main retreival systems are retreiving BEITs."
      ],
      "metadata": {
        "id": "qg5JMRYe9-fH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TF-IDF Retreival"
      ],
      "metadata": {
        "id": "nOX_ND8tWIua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining cosine function to compute cosine of angle between two vectors in space:\n"
      ],
      "metadata": {
        "id": "VzFGF62QYW6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cosine(v1,v2):\n",
        "    return np.inner(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
      ],
      "metadata": {
        "id": "93XKKu818gp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "get_most_similars returns k most similar vectos to query_vector based on similarity_func:\n"
      ],
      "metadata": {
        "id": "lAVZh17L3PTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_most_similars(document_vectors, query_vector, similarity_func, k=10):\n",
        "    tops = list()\n",
        "    for i, vec in enumerate(document_vectors):\n",
        "        similarity = similarity_func(query_vector, vec)\n",
        "        if not np.isnan(similarity):\n",
        "          tops.append([similarity, all_data[i]])\n",
        "    tops = np.array(tops)\n",
        "    args = np.argsort(tops[:, 0])[::-1]\n",
        "    return list(tops[args[:k]])"
      ],
      "metadata": {
        "id": "BVNrHaMD9VDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(analyzer= lambda x: sent_pre_process(x, remove_stopwords=True))\n",
        "tfidf_data = tfidf.fit_transform(all_data)\n",
        "tfidf_data = tfidf_data.toarray()"
      ],
      "metadata": {
        "id": "hNs7OmLAwg4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lls3kNlmJKeK",
        "outputId": "ac1a5b00-4c8f-48a4-e7ed-660f3133fdb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6566, 10797)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tfidf_retrieval(str, k=10):\n",
        "  tfidf_str = tfidf.transform([str]).toarray()[0]\n",
        "  return pd.DataFrame(get_most_similars(tfidf_data, tfidf_str, get_cosine, k))"
      ],
      "metadata": {
        "id": "l9mPI_LW9XpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_retrieval('دلم خانه‌ی مهر یار است و بس', k=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oc0Zt0K9snq",
        "outputId": "39ffccfd-e823-43a2-995d-62d8522e0d09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     0                                                  1\n",
              "0   0.6832235115151075  دلم خانهٔ مهر یار است و بس\\nاز آن می‌نگنجد در ...\n",
              "1   0.5413772731987289                                        گفت: ای یار\n",
              "2   0.5413772731987289                                      گفت: ای یاران\n",
              "3   0.3613019833857258                                   گفت: ای یار عزیز\n",
              "4    0.310908529569272  خرابت کند شاهد خانه کن\\nبرو خانه آباد گردان به زن\n",
              "5  0.30932197746696155  یکی از لوازم صحبت آن است که خانه بپردازی یا با...\n",
              "6   0.2855158030134369  رهی رو که بینی طریق رجا\\nتو و مهر شمع از کجا ت...\n",
              "7   0.2754478022726963   بر سر لوح او نبشته به زر\\nجور استاد به ز مهر پدر\n",
              "8  0.27440282720818304                               منجمی به خانه در آمد\n",
              "9  0.26910487285512996                              صاحب دعوت گفت: ای یار"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-34d2ad3f-91bb-4169-a2d2-06b1975d05c5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.6832235115151075</td>\n",
              "      <td>دلم خانهٔ مهر یار است و بس\\nاز آن می‌نگنجد در ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.5413772731987289</td>\n",
              "      <td>گفت: ای یار</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.5413772731987289</td>\n",
              "      <td>گفت: ای یاران</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.3613019833857258</td>\n",
              "      <td>گفت: ای یار عزیز</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.310908529569272</td>\n",
              "      <td>خرابت کند شاهد خانه کن\\nبرو خانه آباد گردان به زن</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.30932197746696155</td>\n",
              "      <td>یکی از لوازم صحبت آن است که خانه بپردازی یا با...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.2855158030134369</td>\n",
              "      <td>رهی رو که بینی طریق رجا\\nتو و مهر شمع از کجا ت...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.2754478022726963</td>\n",
              "      <td>بر سر لوح او نبشته به زر\\nجور استاد به ز مهر پدر</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.27440282720818304</td>\n",
              "      <td>منجمی به خانه در آمد</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.26910487285512996</td>\n",
              "      <td>صاحب دعوت گفت: ای یار</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34d2ad3f-91bb-4169-a2d2-06b1975d05c5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-34d2ad3f-91bb-4169-a2d2-06b1975d05c5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-34d2ad3f-91bb-4169-a2d2-06b1975d05c5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer-based Model"
      ],
      "metadata": {
        "id": "t5Wfi8WS4rzJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this part, we create a model based on [Pars-BERT](https://github.com/hooshvare/parsbert), a pretrained transformer model based on BERT."
      ],
      "metadata": {
        "id": "1XzbzJNX4aZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U sentence-transformers"
      ],
      "metadata": {
        "id": "eLL4pZfy4t6Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0de39d9c-5222-42ad-f0b5-e25f273a200e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence-transformers-2.2.0.tar.gz (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 4.5 MB/s \n",
            "\u001b[?25hCollecting transformers<5.0.0,>=4.6.0\n",
            "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 15.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.64.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.12.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.3)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 54.6 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 13.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (4.1.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.7.1)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 53.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.6.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (4.11.4)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 67.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (1.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
            "Building wheels for collected packages: sentence-transformers\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.0-py3-none-any.whl size=120747 sha256=cfc12af6539a2b9374195e70231c8d23db4e2daf5f17fb3483b3f4dd2183b1d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/c0/df/b6873ab7aac3f2465aa9144b6b4c41c4391cfecc027c8b07e7\n",
            "Successfully built sentence-transformers\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers, sentencepiece, sentence-transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 sentence-transformers-2.2.0 sentencepiece-0.1.96 tokenizers-0.12.1 transformers-4.20.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sentence_transformers as st\n",
        "import itertools"
      ],
      "metadata": {
        "id": "mHh6_6J94w_D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bb3f4ea-61b0-4042-9feb-46f943f1df1f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/huggingface_hub/snapshot_download.py:11: FutureWarning: snapshot_download.py has been made private and will no longer be available from version 0.11. Please use `from huggingface_hub import snapshot_download` to import the only public function in this module. Other members of the file may be changed without a deprecation notice.\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class my_transformer:\n",
        "    def __init__(self, document):\n",
        "        self.data = document\n",
        "        self.x = st.models.Transformer('HooshvareLab/bert-fa-zwnj-base')\n",
        "        self.model = st.SentenceTransformer(modules=[self.x, st.models.Pooling(self.x.get_word_embedding_dimension())])\n",
        "        self.processed_data = pre_process(self.data, remove_stopwords=True, put_index=True, MIN_COUNT=0)\n",
        "        self.processed_data_index = [(' '.join(x[0]), x[1]) for x in self.processed_data]\n",
        "        self.processed_data = [' '.join(x[0]) for x in self.processed_data]\n",
        "        self.vectors = self.model.encode(self.processed_data)\n",
        "    \n",
        "    def search(self, query, k=10):\n",
        "        pre_processed_query = sent_pre_process(query, remove_stopwords=True)\n",
        "        joint_processed_query = ' '.join(pre_processed_query)\n",
        "        tops = list()\n",
        "        query_encode = self.model.encode(joint_processed_query)\n",
        "        sims = st.util.cos_sim(query_encode, self.vectors).numpy()[0]\n",
        "        indexes = np.argsort(sims)[::-1][:k]\n",
        "        tops = list()\n",
        "        for ind in indexes:\n",
        "            tops.append((sims[ind], self.data[self.processed_data_index[ind][1]]))\n",
        "        return tops"
      ],
      "metadata": {
        "id": "JMd8sKCC4yl5"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_model = my_transformer(all_data)"
      ],
      "metadata": {
        "id": "Rm-GS65V4z9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_model.search('به نام خداوند جان آفرین')"
      ],
      "metadata": {
        "id": "h5ih_vTg41Nx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Embedding"
      ],
      "metadata": {
        "id": "OzM4n6pznPyJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll use Word2Vec as our model for for Word Embedding:"
      ],
      "metadata": {
        "id": "lRoXjJXQ5GLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "DfQxws4kNtzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_all_words(document):\n",
        "    all_words = {}\n",
        "    for line in pre_process(document['poem'], remove_stopwords=True):\n",
        "        for w in line:\n",
        "            if w not in all_words:\n",
        "                all_words[w] = 0\n",
        "            all_words[w] += 1\n",
        "    return all_words"
      ],
      "metadata": {
        "id": "zD2X62_tN8QV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pre_process(boostan_data['poem']))"
      ],
      "metadata": {
        "id": "afxvqD91I017"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools"
      ],
      "metadata": {
        "id": "IOjLkWWcMSvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "idf = TfidfTransformer(smooth_idf=True,use_idf=True) \n",
        "idf.fit(tf_data);"
      ],
      "metadata": {
        "id": "3p_AKZoNF6hZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idf_data = idf.idf_\n",
        "idf_data.shape\n",
        "idf_dataframe = pd.Series(idf_data, index=tf.get_feature_names())\n",
        "idf_dataframe.head()"
      ],
      "metadata": {
        "id": "D0VvclsIGOWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class my_word2vec:\n",
        "    def __init__(self, document):\n",
        "        self.data = document\n",
        "        # all_words = get_all_words(document)\n",
        "        x = pre_process(document, remove_stopwords=True)\n",
        "        self.model = Word2Vec(x)\n",
        "\n",
        "    def get_most_similar_word_to_word(self, word):\n",
        "        return self.model.wv.most_similar(word)\n",
        "\n",
        "    def get_similarity(self, query, line):\n",
        "        pre_processed_query = sent_pre_process(query, remove_stopwords=True)\n",
        "        pre_processed_line = sent_pre_process(line, remove_stopwords=True)\n",
        "        query_vector = self.word_summation(pre_processed_query)\n",
        "        line_vector = self.word_summation(pre_processed_line)\n",
        "        return get_cosine(query_vector, line_vector)\n",
        "\n",
        "    def word_summation(self, sent):\n",
        "        vector = np.zeros(self.model.wv.vector_size, dtype=np.float64)\n",
        "        weight_sum = 0\n",
        "        for word in sent:\n",
        "          try:\n",
        "            weight = idf_dataframe[word]\n",
        "            vector += self.model.wv[word] * weight\n",
        "            weight_sum += weight\n",
        "          except:\n",
        "            pass\n",
        "        return vector / weight_sum\n",
        "\n",
        "    def search(self, sentence, k=10):\n",
        "        tops = list()\n",
        "        for line in self.data:\n",
        "            similarity = self.get_similarity(sentence, line)\n",
        "            if not np.isnan(similarity):\n",
        "              tops.append([similarity, line])\n",
        "        tops = np.array(tops)\n",
        "        args = np.argsort(tops[:, 0])[::-1]\n",
        "        return list(tops[args[:k]])\n",
        "\n",
        "    def get_vec(self, doc):\n",
        "        return self.model.infer_vector(pre_process(doc)[0])"
      ],
      "metadata": {
        "id": "ewy31-_D2O9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = my_word2vec(all_data)"
      ],
      "metadata": {
        "id": "iUHgtPtXvTcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beit = 'به نام خداوند جان و خرد'"
      ],
      "metadata": {
        "id": "pGyJeUQm5mQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in model.search(beit):\n",
        "    print(x[0], x[1])"
      ],
      "metadata": {
        "id": "9av51TeTlsyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MMR and Evaluating Model"
      ],
      "metadata": {
        "id": "r1F_QOe75QSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_queries = pd.read_csv('HW3-Dataset.csv', names=['query', 'user1', 'user2', 'user3'])\n",
        "queries = []"
      ],
      "metadata": {
        "id": "15_aICkczPcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for row in dataset_queries['query'].dropna():\n",
        "    if row.startswith('q'):\n",
        "        queries.append(row.split('\"')[-2])"
      ],
      "metadata": {
        "id": "UHgt0Js5zn4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "xlsx_extract, creates a xlxx file for each of four methods, containing 10 responses for each of 10 queries. We will use these files to label our retreived documents.\n"
      ],
      "metadata": {
        "id": "I_Y0ux1m5juX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def xlsx_extract(output, response_dict):\n",
        "    dataframe_list = []\n",
        "    i = 1\n",
        "    for key, value in response_dict.items():\n",
        "        dataframe_list.append(f'q{i} = \"{key}\"')\n",
        "        for sent in value:\n",
        "            dataframe_list.append(sent)\n",
        "        i += 1\n",
        "\n",
        "    df = pd.DataFrame({'query/response': dataframe_list,\n",
        "                'user1': np.nan,\n",
        "                'user2': np.nan,\n",
        "                'user3': np.nan})\n",
        "    df.to_excel(output, index=False)  "
      ],
      "metadata": {
        "id": "13u3JYrZ2kTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting responses for each of four models:"
      ],
      "metadata": {
        "id": "xpMgrBW0553X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# boolean_retrieval extract xlsx\n",
        "response_dict = {}\n",
        "\n",
        "for query in queries:\n",
        "    response = boolean_retrieval(query)\n",
        "    response_dict[query] = []\n",
        "    for number, sent in response:\n",
        "        response_dict[query].append(sent)\n",
        "\n",
        "xlsx_extract('boolean.xlsx', response_dict)"
      ],
      "metadata": {
        "id": "mWAh8cO31tUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tfidf_retrieval extract xlsx\n",
        "response_dict = {}\n",
        "\n",
        "for query in queries:\n",
        "    response = tfidf_retrieval(query)\n",
        "    response_dict[query] = []\n",
        "    for sent in response[1]:\n",
        "        response_dict[query].append(sent)\n",
        "\n",
        "xlsx_extract('tfidf.xlsx', response_dict)"
      ],
      "metadata": {
        "id": "-E11wIHC4OR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queries"
      ],
      "metadata": {
        "id": "1wJkCNM0CdQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# word2vec extract xlsx\n",
        "response_dict = {}\n",
        "model = my_word2vec(all_data)\n",
        "\n",
        "for query in queries:\n",
        "    response = model.search(query)\n",
        "    response_dict[query] = []\n",
        "    for sent in response:\n",
        "        response_dict[query].append(sent[1])\n",
        "\n",
        "xlsx_extract('word2vec.xlsx', response_dict)"
      ],
      "metadata": {
        "id": "cJ15YO0D9-Xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transformer extract xlsx\n",
        "response_dict = {}\n",
        "model = my_transformer(all_data)\n",
        "\n",
        "for query in queries:\n",
        "    response = model.search(query)\n",
        "    response_dict[query] = []\n",
        "    for sent in response:\n",
        "        response_dict[query].append(sent[1])\n",
        "\n",
        "xlsx_extract('transformer.xlsx', response_dict)"
      ],
      "metadata": {
        "id": "ubq1tdFVoMZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computing MRRs:"
      ],
      "metadata": {
        "id": "LbcAmlDxGRoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MRR\n",
        "\n",
        "methods = ['boolean', 'tfidf', 'word2vec', 'transformer']\n",
        "\n",
        "for method in methods:\n",
        "  df = pd.read_csv(f'labeled-output/{method}-labeled.csv', names=['query', 'user1', 'user2', 'user3'], encoding='utf-8')\n",
        "  user1_vector = np.array(df['user1'])[1:]\n",
        "  user2_vector = np.array(df['user2'])[1:]\n",
        "  user3_vector = np.array(df['user3'])[1:]\n",
        "  score_vector = np.concatenate([user1_vector.reshape([10, 11])[:, 1:],\n",
        "                    user2_vector.reshape([10, 11])[:, 1:],\n",
        "                    user3_vector.reshape([10, 11])[:, 1:]])\n",
        "\n",
        "  score_list = []\n",
        "\n",
        "  for score in score_vector:\n",
        "      for i, x in enumerate(score):\n",
        "          if x == '1':\n",
        "              score_list.append(1/(i + 1))\n",
        "              break\n",
        "          elif i == 9:\n",
        "              score_list.append(0)\n",
        "\n",
        "  MRR_score = sum(score_list) / len(score_list)\n",
        "\n",
        "  print(f'MRR score for method {method} is: {MRR_score:.3f}')"
      ],
      "metadata": {
        "id": "TXXsHsxjFWw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phase 2: Classification and Clustering"
      ],
      "metadata": {
        "id": "_wC62OVRMaSa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "id": "cY-bLJBwMfaI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = boostan_data.drop(columns = ['section'])"
      ],
      "metadata": {
        "id": "z5vJyDw_JRBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.chapter.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpWgx74SMqUs",
        "outputId": "eae18a62-73be-46b0-ce3d-9df3d3c65f7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1     910\n",
              "4     524\n",
              "2     502\n",
              "7     445\n",
              "3     365\n",
              "9     336\n",
              "8     275\n",
              "0     219\n",
              "5     203\n",
              "6     172\n",
              "10    113\n",
              "Name: chapter, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, our classes are imbalanced and Chapter 1 of boostan has a larger amount of verses in it."
      ],
      "metadata": {
        "id": "bBzVsy-TQ7X9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting test and train data:"
      ],
      "metadata": {
        "id": "1GjuJQkAMt-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "VUC_PiH2MtA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split test-train data\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['poem'], data['chapter'], test_size=0.2, random_state=23)"
      ],
      "metadata": {
        "id": "_r61hsEmM0u7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rducJWGKM5F4",
        "outputId": "a2829498-ee79-4c23-bb93-5466a16b3e36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3251,), (813,), (3251,), (813,))"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because we are dealing with an imbalanced classification problem and our main metric is F1 score and True Positives are important to us, we give each class a weight and in our `pytorch` models, use them in CrossEntropyLoss to consider this imbalanceness in training."
      ],
      "metadata": {
        "id": "qazNJa7RGkyg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_weight = data['chapter'].count() / data['chapter'].value_counts()\n",
        "class_weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLS59kaTGjwK",
        "outputId": "79440a96-df7e-40a6-feed-3c695b447b30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1      4.465934\n",
              "4      7.755725\n",
              "2      8.095618\n",
              "7      9.132584\n",
              "3     11.134247\n",
              "9     12.095238\n",
              "8     14.778182\n",
              "0     18.557078\n",
              "5     20.019704\n",
              "6     23.627907\n",
              "10    35.964602\n",
              "Name: chapter, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification"
      ],
      "metadata": {
        "id": "010_x56AF-Sc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "k3EICuY74PwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Number of Classes that we classify:"
      ],
      "metadata": {
        "id": "mqI68TvQYMV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_class = 11"
      ],
      "metadata": {
        "id": "u1Da-jjdYL9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vectorizing data using TF-IDF:"
      ],
      "metadata": {
        "id": "dq8GZ_mINJMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer(analyzer=lambda x: sent_pre_process(x, remove_stopwords=True))\n",
        "tfidf_X_train = tfidf.fit_transform(X_train).toarray()\n",
        "tfidf_X_test = tfidf.transform(X_test).toarray()\n",
        "tfidf_X_train.shape, tfidf_X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwx48IiNNP6v",
        "outputId": "c47108a4-1b30-43c2-a7e4-0fe26e0c67aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3251, 6124), (813, 6124))"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining functions for printing metrics and plotting confusion matrices:"
      ],
      "metadata": {
        "id": "mizEsYmwazTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we'll use this function for evaluation of metrics: accuracy, precision, recall, and f1 of our models in the future\n",
        "def print_metrics_evaluation(true_y, pred_y, model_name=None, average='macro'):\n",
        "    if model_name is not None:\n",
        "        print(f'{model_name}:')\n",
        "    print(\n",
        "f'''accuracy_score = {accuracy_score(true_y, pred_y)}\n",
        "precision_score = {precision_score(true_y, pred_y, average=average)}\n",
        "recall_score = {recall_score(true_y, pred_y, average=average)}\n",
        "f1_score = {f1_score(true_y, pred_y, average=average)}\n",
        "''')"
      ],
      "metadata": {
        "id": "0B3Sq_TK4EC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for plotting confusion matrix \n",
        "def plot_confusion_matrix(y_test, test_pred):\n",
        "  sns.heatmap(confusion_matrix(y_test, test_pred), annot=True, cmap='Accent');"
      ],
      "metadata": {
        "id": "14_zwn9Ma5NJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tree Classifiers"
      ],
      "metadata": {
        "id": "g1m7P9bisGCe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### DecisionTreeClassifier:\n",
        "DecisionTreeClassifier is basic tree based classifier in Sklearn llibrary:"
      ],
      "metadata": {
        "id": "DPgZlPcgQiEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "clf = DecisionTreeClassifier(random_state=0, min_samples_split=20, class_weight=class_weight.to_dict())\n",
        "clf.fit(tfidf_X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwnHPopmHejT",
        "outputId": "d70e6bed-6828-4a68-b47d-15631e0537d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(class_weight={0: 18.557077625570777,\n",
              "                                     1: 4.465934065934066, 2: 8.095617529880478,\n",
              "                                     3: 11.134246575342466,\n",
              "                                     4: 7.755725190839694,\n",
              "                                     5: 20.019704433497537,\n",
              "                                     6: 23.627906976744185,\n",
              "                                     7: 9.132584269662921,\n",
              "                                     8: 14.778181818181817,\n",
              "                                     9: 12.095238095238095,\n",
              "                                     10: 35.9646017699115},\n",
              "                       min_samples_split=20, random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_pred = clf.predict(tfidf_X_train)\n",
        "test_pred = clf.predict(tfidf_X_test)\n",
        "\n",
        "print_metrics_evaluation(y_train, train_pred, model_name='Train Set', average='macro')\n",
        "print_metrics_evaluation(y_test, test_pred, model_name='Test Set', average='macro')\n",
        "plot_confusion_matrix(y_test, test_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "iu9zgXsRIkhK",
        "outputId": "be0f18ed-f101-4819-d81b-13cbe474382e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Set:\n",
            "accuracy_score = 0.6927099354044909\n",
            "precision_score = 0.6748283995188987\n",
            "recall_score = 0.7674640294573823\n",
            "f1_score = 0.6965800942953589\n",
            "\n",
            "Test Set:\n",
            "accuracy_score = 0.2017220172201722\n",
            "precision_score = 0.17957291521974694\n",
            "recall_score = 0.19077614996897935\n",
            "f1_score = 0.17948128022149423\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### XGBoost:\n",
        "XGBoost is a Desicion-Tree based model which benefits from ensembles and gradient boosting:"
      ],
      "metadata": {
        "id": "nj3IHGV47WWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb"
      ],
      "metadata": {
        "id": "j0csM-R8sEL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D_train = xgb.DMatrix(tfidf_X_train, label=y_train)\n",
        "D_test = xgb.DMatrix(tfidf_X_test, label=y_test)"
      ],
      "metadata": {
        "id": "5RiDRJfGyezr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "step = 20\n",
        "\n",
        "param = {\n",
        "    'eta': 0.3,\n",
        "    'objective': 'multi:softmax',\n",
        "    'num_class': num_class\n",
        "}\n",
        "\n",
        "model = xgb.train(param, D_train, step)"
      ],
      "metadata": {
        "id": "ywgIkuqL1rAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_preds = model.predict(D_train)\n",
        "test_preds = model.predict(D_test)\n",
        "\n",
        "print_metrics_evaluation(y_train, train_preds, model_name='Train Set', average='macro')\n",
        "print_metrics_evaluation(y_test, test_preds, model_name='Test Set', average='macro')\n",
        "plot_confusion_matrix(y_test, test_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "0yVS83fbC7Tu",
        "outputId": "62a57871-b5ab-4d68-9fb1-e0f21283caff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Set:\n",
            "accuracy_score = 0.4290987388495847\n",
            "precision_score = 0.6636532776698513\n",
            "recall_score = 0.32633134727017227\n",
            "f1_score = 0.3895537243545472\n",
            "\n",
            "Test Set:\n",
            "accuracy_score = 0.27060270602706027\n",
            "precision_score = 0.2821784902468437\n",
            "recall_score = 0.17441582112500734\n",
            "f1_score = 0.1809264007395968\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deep Neural Network models:"
      ],
      "metadata": {
        "id": "Qui7p0PDP9DC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need validation dataset for this part:"
      ],
      "metadata": {
        "id": "-7cLAkozRnJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=23)"
      ],
      "metadata": {
        "id": "Nb6OmoKEQqse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_X_val = tfidf.transform(X_val).toarray()\n",
        "tfidf_X_train = tfidf.transform(X_train).toarray()"
      ],
      "metadata": {
        "id": "mjbLS-gVVc4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Pytorch:\n",
        "(Unfortunately this model gets poor f1 scores but we have kept it for showing our different models that we tried.)"
      ],
      "metadata": {
        "id": "A_P7mTz1VRy3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing required libraries"
      ],
      "metadata": {
        "id": "dV96phqnQUZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import tqdm\n",
        "\n",
        "from typing import Tuple\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "aHnkbLf7GA3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "for using GPU if possible:"
      ],
      "metadata": {
        "id": "-FNtWXBkQdfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUv61GocQbJP",
        "outputId": "bf16db0e-3cd3-486d-b64b-6b60d9011524"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining a simple Dataset class for our data used by pytorch models:"
      ],
      "metadata": {
        "id": "fehHwNTrQmue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BoostanDataset(Dataset):\n",
        "    def __init__(self, X: np.ndarray, Y: np.ndarray):\n",
        "        self.X = torch.from_numpy(X)\n",
        "        self.Y = torch.from_numpy(Y)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self.X.shape[0]\n",
        "\n",
        "    def __getitem__(self, i: int) -> Tuple[torch.Tensor, ...]:\n",
        "        return self.X[i], self.Y[i]"
      ],
      "metadata": {
        "id": "eCm2d_aqQkpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define a simple neural network model consisting multiple Linear layers, ReLU activation functions and Dropout for preventing overfitting on training data.  "
      ],
      "metadata": {
        "id": "ORlIW8vxSftZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BoostanClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, num_class, dropout=0.5):\n",
        "        super().__init__()\n",
        "        self.input_size = input_size\n",
        "        self.num_class = num_class\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.lnn = nn.Sequential(\n",
        "            nn.Linear(self.input_size, 64),\n",
        "            nn.ReLU(),\n",
        "            self.dropout,\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            self.dropout,\n",
        "            nn.Linear(32, num_class),\n",
        "        )\n",
        "        \n",
        "    def forward(self, x: torch.tensor):\n",
        "        x = x.view(-1, self.input_size)\n",
        "        return self.lnn(x)\n",
        "\n",
        "    def predict(self, x):\n",
        "        return self.forward(x)"
      ],
      "metadata": {
        "id": "zpMVRw2QSPwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "\n",
        "feature_selector = SelectKBest(chi2, k=40)\n",
        "train_X = feature_selector.fit_transform(tfidf_X_train, y_train)\n",
        "val_X = feature_selector.transform(tfidf_X_val)\n",
        "test_X = feature_selector.transform(tfidf_X_test)"
      ],
      "metadata": {
        "id": "f_upv8WMkDct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X.shape, val_X.shape, test_X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzeM4x-Ok5VD",
        "outputId": "5dbbab78-1e0e-465d-c92c-fac01c45ded2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2080, 40), (520, 40), (813, 40))"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Dataset and Dataloader from our training and validation and test data:"
      ],
      "metadata": {
        "id": "kqoS7C-xTfpx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = 'chapter'\n",
        "batch_size = 32\n",
        "\n",
        "train_set = BoostanDataset(train_X, y_train.to_numpy())\n",
        "val_set = BoostanDataset(val_X, y_val.to_numpy())\n",
        "test_set = BoostanDataset(test_X, y_test.to_numpy())\n",
        "\n",
        "train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=False)\n",
        "val_loader = DataLoader(dataset=val_set, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "4c7fswUKTbwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note how we used class weights in Loss funcion in order to get a better F1 score:"
      ],
      "metadata": {
        "id": "pwLHmiWXaTuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setting config:\n",
        "model = BoostanClassifier(test_X.shape[1], num_class).to(device).double()\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "lr=1e-4\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n"
      ],
      "metadata": {
        "id": "1JNkKOHtaN-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating train and validate functions for more convenience."
      ],
      "metadata": {
        "id": "wCdX5SEhWxfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, criterion, optimizer, epoch):\n",
        "    train_loss = 0\n",
        "    N_train = len(train_loader.dataset)\n",
        "\n",
        "    model.train()\n",
        "    with tqdm.tqdm(enumerate(train_loader), total=len(train_loader)) as pbar:\n",
        "        for i, (x, y) in pbar:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            p = model(x)\n",
        "            \n",
        "            loss = criterion(p, y)\n",
        "            train_loss += loss.item() * len(x)\n",
        "\n",
        "            pbar.set_description(f'Epoch:{epoch}, Train Loss: {train_loss / N_train:.3e}')\n",
        "            \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    \n",
        "    train_loss /= N_train\n",
        "    return train_loss\n",
        "\n",
        "\n",
        "def validate(model, criterion, epoch):\n",
        "    val_loss = 0\n",
        "    N_val = len(val_loader.dataset)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad(), tqdm.tqdm(enumerate(val_loader), total=len(val_loader)) as pbar:\n",
        "        for i, (x, y) in pbar:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            p = model(x)\n",
        "\n",
        "            loss = criterion(p, y)\n",
        "            val_loss += loss.item() * len(x)\n",
        "\n",
        "            pbar.set_description(f'Epoch:{epoch}, Val Loss: {val_loss / N_val:.3e}')\n",
        "    \n",
        "    print('-------------------------------------------------------------------')\n",
        "    val_loss /= N_val\n",
        "    return val_loss"
      ],
      "metadata": {
        "id": "heVSbk4MWyDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function trains given pytorch model and returns the best result of training process, plots learning curves for train and validation sets and finally prints metrics' values."
      ],
      "metadata": {
        "id": "PKLJ7UO4b2r-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def do_expriment(model, optimizer, num_epochs, model_name):\n",
        "\n",
        "    train_loss_arr, val_loss_arr = np.zeros(num_epochs), np.zeros(num_epochs)\n",
        "\n",
        "    val_loss_min = float('inf')\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = train(model, criterion, optimizer, epoch)\n",
        "        val_loss = validate(model, criterion, epoch)\n",
        "\n",
        "        train_loss_arr[epoch] = train_loss\n",
        "        val_loss_arr[epoch] = val_loss\n",
        "\n",
        "        if val_loss <= val_loss_min:\n",
        "            torch.save(model.state_dict(), f'{model_name}.pt')\n",
        "            val_loss_min = val_loss\n",
        "\n",
        "    # load best model during different epochs\n",
        "    # model.load_state_dict(torch.load(f'{model_name}.pt'))\n",
        "\n",
        "    # metrics\n",
        "    X_train, Y_train = train_loader.dataset[:]\n",
        "    X_val, Y_val = val_loader.dataset[:]\n",
        "\n",
        "    model = model.to('cpu')\n",
        "\n",
        "    train_preds = model(X_train).argmax(dim=1)\n",
        "    val_preds = model(X_val).argmax(dim=1)\n",
        "\n",
        "    plt.plot(train_loss_arr, label='train')\n",
        "    plt.plot(val_loss_arr, label='val')\n",
        "    plt.legend();\n",
        "\n",
        "    print_metrics_evaluation(Y_train.detach(), model(X_train).argmax(dim=1).detach(), f'{model_name}: Metrics on Training Data')\n",
        "    print_metrics_evaluation(Y_val.detach(), model(X_val).argmax(dim=1).detach(), f'{model_name}: Metrics on Validation Data')\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    return train_loss_arr, val_loss_arr, model"
      ],
      "metadata": {
        "id": "8pv78k8Mb2TH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss_arr, val_loss_arr, model = do_expriment(model, optimizer, num_epochs=100, model_name='PytorchModel')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Ez9zbwaSfmYE",
        "outputId": "981ce485-c626-4af5-d0f4-401a68da4d65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:0, Train Loss: 2.388e+00: 100%|██████████| 65/65 [00:00<00:00, 149.99it/s]\n",
            "Epoch:0, Val Loss: 2.384e+00: 100%|██████████| 17/17 [00:00<00:00, 298.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:1, Train Loss: 2.381e+00: 100%|██████████| 65/65 [00:00<00:00, 108.70it/s]\n",
            "Epoch:1, Val Loss: 2.378e+00: 100%|██████████| 17/17 [00:00<00:00, 328.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:2, Train Loss: 2.377e+00: 100%|██████████| 65/65 [00:00<00:00, 140.74it/s]\n",
            "Epoch:2, Val Loss: 2.371e+00: 100%|██████████| 17/17 [00:00<00:00, 287.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:3, Train Loss: 2.370e+00: 100%|██████████| 65/65 [00:00<00:00, 137.53it/s]\n",
            "Epoch:3, Val Loss: 2.363e+00: 100%|██████████| 17/17 [00:00<00:00, 358.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:4, Train Loss: 2.360e+00: 100%|██████████| 65/65 [00:00<00:00, 122.83it/s]\n",
            "Epoch:4, Val Loss: 2.355e+00: 100%|██████████| 17/17 [00:00<00:00, 221.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:5, Train Loss: 2.353e+00: 100%|██████████| 65/65 [00:00<00:00, 141.73it/s]\n",
            "Epoch:5, Val Loss: 2.347e+00: 100%|██████████| 17/17 [00:00<00:00, 321.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:6, Train Loss: 2.341e+00: 100%|██████████| 65/65 [00:00<00:00, 142.48it/s]\n",
            "Epoch:6, Val Loss: 2.338e+00: 100%|██████████| 17/17 [00:00<00:00, 221.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:7, Train Loss: 2.334e+00: 100%|██████████| 65/65 [00:00<00:00, 135.74it/s]\n",
            "Epoch:7, Val Loss: 2.330e+00: 100%|██████████| 17/17 [00:00<00:00, 280.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:8, Train Loss: 2.326e+00: 100%|██████████| 65/65 [00:00<00:00, 130.04it/s]\n",
            "Epoch:8, Val Loss: 2.322e+00: 100%|██████████| 17/17 [00:00<00:00, 225.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:9, Train Loss: 2.319e+00: 100%|██████████| 65/65 [00:00<00:00, 125.83it/s]\n",
            "Epoch:9, Val Loss: 2.314e+00: 100%|██████████| 17/17 [00:00<00:00, 232.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:10, Train Loss: 2.307e+00: 100%|██████████| 65/65 [00:00<00:00, 136.03it/s]\n",
            "Epoch:10, Val Loss: 2.307e+00: 100%|██████████| 17/17 [00:00<00:00, 208.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:11, Train Loss: 2.296e+00: 100%|██████████| 65/65 [00:00<00:00, 124.66it/s]\n",
            "Epoch:11, Val Loss: 2.299e+00: 100%|██████████| 17/17 [00:00<00:00, 250.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:12, Train Loss: 2.293e+00: 100%|██████████| 65/65 [00:00<00:00, 150.32it/s]\n",
            "Epoch:12, Val Loss: 2.293e+00: 100%|██████████| 17/17 [00:00<00:00, 203.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:13, Train Loss: 2.291e+00: 100%|██████████| 65/65 [00:00<00:00, 161.68it/s]\n",
            "Epoch:13, Val Loss: 2.288e+00: 100%|██████████| 17/17 [00:00<00:00, 230.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:14, Train Loss: 2.283e+00: 100%|██████████| 65/65 [00:00<00:00, 162.77it/s]\n",
            "Epoch:14, Val Loss: 2.283e+00: 100%|██████████| 17/17 [00:00<00:00, 202.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:15, Train Loss: 2.277e+00: 100%|██████████| 65/65 [00:00<00:00, 164.40it/s]\n",
            "Epoch:15, Val Loss: 2.279e+00: 100%|██████████| 17/17 [00:00<00:00, 239.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:16, Train Loss: 2.274e+00: 100%|██████████| 65/65 [00:00<00:00, 162.65it/s]\n",
            "Epoch:16, Val Loss: 2.276e+00: 100%|██████████| 17/17 [00:00<00:00, 245.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:17, Train Loss: 2.272e+00: 100%|██████████| 65/65 [00:00<00:00, 167.59it/s]\n",
            "Epoch:17, Val Loss: 2.273e+00: 100%|██████████| 17/17 [00:00<00:00, 222.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:18, Train Loss: 2.271e+00: 100%|██████████| 65/65 [00:00<00:00, 170.93it/s]\n",
            "Epoch:18, Val Loss: 2.271e+00: 100%|██████████| 17/17 [00:00<00:00, 233.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:19, Train Loss: 2.269e+00: 100%|██████████| 65/65 [00:00<00:00, 162.28it/s]\n",
            "Epoch:19, Val Loss: 2.270e+00: 100%|██████████| 17/17 [00:00<00:00, 278.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:20, Train Loss: 2.274e+00: 100%|██████████| 65/65 [00:00<00:00, 167.44it/s]\n",
            "Epoch:20, Val Loss: 2.269e+00: 100%|██████████| 17/17 [00:00<00:00, 251.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:21, Train Loss: 2.265e+00: 100%|██████████| 65/65 [00:00<00:00, 160.26it/s]\n",
            "Epoch:21, Val Loss: 2.268e+00: 100%|██████████| 17/17 [00:00<00:00, 214.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:22, Train Loss: 2.268e+00: 100%|██████████| 65/65 [00:00<00:00, 161.58it/s]\n",
            "Epoch:22, Val Loss: 2.267e+00: 100%|██████████| 17/17 [00:00<00:00, 249.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:23, Train Loss: 2.267e+00: 100%|██████████| 65/65 [00:00<00:00, 163.93it/s]\n",
            "Epoch:23, Val Loss: 2.267e+00: 100%|██████████| 17/17 [00:00<00:00, 205.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:24, Train Loss: 2.264e+00: 100%|██████████| 65/65 [00:00<00:00, 160.63it/s]\n",
            "Epoch:24, Val Loss: 2.266e+00: 100%|██████████| 17/17 [00:00<00:00, 229.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:25, Train Loss: 2.263e+00: 100%|██████████| 65/65 [00:00<00:00, 160.56it/s]\n",
            "Epoch:25, Val Loss: 2.266e+00: 100%|██████████| 17/17 [00:00<00:00, 230.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:26, Train Loss: 2.256e+00: 100%|██████████| 65/65 [00:00<00:00, 163.83it/s]\n",
            "Epoch:26, Val Loss: 2.266e+00: 100%|██████████| 17/17 [00:00<00:00, 200.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:27, Train Loss: 2.257e+00: 100%|██████████| 65/65 [00:00<00:00, 164.17it/s]\n",
            "Epoch:27, Val Loss: 2.265e+00: 100%|██████████| 17/17 [00:00<00:00, 215.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:28, Train Loss: 2.260e+00: 100%|██████████| 65/65 [00:00<00:00, 158.58it/s]\n",
            "Epoch:28, Val Loss: 2.265e+00: 100%|██████████| 17/17 [00:00<00:00, 209.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:29, Train Loss: 2.263e+00: 100%|██████████| 65/65 [00:00<00:00, 166.18it/s]\n",
            "Epoch:29, Val Loss: 2.265e+00: 100%|██████████| 17/17 [00:00<00:00, 237.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:30, Train Loss: 2.262e+00: 100%|██████████| 65/65 [00:00<00:00, 163.93it/s]\n",
            "Epoch:30, Val Loss: 2.265e+00: 100%|██████████| 17/17 [00:00<00:00, 249.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:31, Train Loss: 2.261e+00: 100%|██████████| 65/65 [00:00<00:00, 163.72it/s]\n",
            "Epoch:31, Val Loss: 2.265e+00: 100%|██████████| 17/17 [00:00<00:00, 233.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:32, Train Loss: 2.262e+00: 100%|██████████| 65/65 [00:00<00:00, 162.46it/s]\n",
            "Epoch:32, Val Loss: 2.264e+00: 100%|██████████| 17/17 [00:00<00:00, 240.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:33, Train Loss: 2.253e+00: 100%|██████████| 65/65 [00:00<00:00, 155.96it/s]\n",
            "Epoch:33, Val Loss: 2.264e+00: 100%|██████████| 17/17 [00:00<00:00, 202.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:34, Train Loss: 2.254e+00: 100%|██████████| 65/65 [00:00<00:00, 164.84it/s]\n",
            "Epoch:34, Val Loss: 2.264e+00: 100%|██████████| 17/17 [00:00<00:00, 204.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:35, Train Loss: 2.256e+00: 100%|██████████| 65/65 [00:00<00:00, 158.28it/s]\n",
            "Epoch:35, Val Loss: 2.264e+00: 100%|██████████| 17/17 [00:00<00:00, 220.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:36, Train Loss: 2.259e+00: 100%|██████████| 65/65 [00:00<00:00, 163.11it/s]\n",
            "Epoch:36, Val Loss: 2.264e+00: 100%|██████████| 17/17 [00:00<00:00, 219.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:37, Train Loss: 2.253e+00: 100%|██████████| 65/65 [00:00<00:00, 147.48it/s]\n",
            "Epoch:37, Val Loss: 2.264e+00: 100%|██████████| 17/17 [00:00<00:00, 199.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:38, Train Loss: 2.248e+00: 100%|██████████| 65/65 [00:00<00:00, 160.10it/s]\n",
            "Epoch:38, Val Loss: 2.264e+00: 100%|██████████| 17/17 [00:00<00:00, 216.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:39, Train Loss: 2.259e+00: 100%|██████████| 65/65 [00:00<00:00, 160.43it/s]\n",
            "Epoch:39, Val Loss: 2.264e+00: 100%|██████████| 17/17 [00:00<00:00, 216.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:40, Train Loss: 2.261e+00: 100%|██████████| 65/65 [00:00<00:00, 158.92it/s]\n",
            "Epoch:40, Val Loss: 2.264e+00: 100%|██████████| 17/17 [00:00<00:00, 245.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:41, Train Loss: 2.259e+00: 100%|██████████| 65/65 [00:00<00:00, 158.49it/s]\n",
            "Epoch:41, Val Loss: 2.264e+00: 100%|██████████| 17/17 [00:00<00:00, 228.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:42, Train Loss: 2.257e+00: 100%|██████████| 65/65 [00:00<00:00, 159.48it/s]\n",
            "Epoch:42, Val Loss: 2.264e+00: 100%|██████████| 17/17 [00:00<00:00, 199.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:43, Train Loss: 2.261e+00: 100%|██████████| 65/65 [00:00<00:00, 159.48it/s]\n",
            "Epoch:43, Val Loss: 2.264e+00: 100%|██████████| 17/17 [00:00<00:00, 214.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:44, Train Loss: 2.249e+00: 100%|██████████| 65/65 [00:00<00:00, 158.26it/s]\n",
            "Epoch:44, Val Loss: 2.264e+00: 100%|██████████| 17/17 [00:00<00:00, 241.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:45, Train Loss: 2.258e+00: 100%|██████████| 65/65 [00:00<00:00, 159.08it/s]\n",
            "Epoch:45, Val Loss: 2.264e+00: 100%|██████████| 17/17 [00:00<00:00, 218.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:46, Train Loss: 2.248e+00: 100%|██████████| 65/65 [00:00<00:00, 152.17it/s]\n",
            "Epoch:46, Val Loss: 2.264e+00: 100%|██████████| 17/17 [00:00<00:00, 217.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:47, Train Loss: 2.256e+00: 100%|██████████| 65/65 [00:00<00:00, 150.55it/s]\n",
            "Epoch:47, Val Loss: 2.264e+00: 100%|██████████| 17/17 [00:00<00:00, 242.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:48, Train Loss: 2.245e+00: 100%|██████████| 65/65 [00:00<00:00, 163.43it/s]\n",
            "Epoch:48, Val Loss: 2.264e+00: 100%|██████████| 17/17 [00:00<00:00, 207.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:49, Train Loss: 2.254e+00: 100%|██████████| 65/65 [00:00<00:00, 158.01it/s]\n",
            "Epoch:49, Val Loss: 2.264e+00: 100%|██████████| 17/17 [00:00<00:00, 328.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:50, Train Loss: 2.251e+00: 100%|██████████| 65/65 [00:00<00:00, 151.52it/s]\n",
            "Epoch:50, Val Loss: 2.264e+00: 100%|██████████| 17/17 [00:00<00:00, 293.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:51, Train Loss: 2.248e+00: 100%|██████████| 65/65 [00:00<00:00, 156.43it/s]\n",
            "Epoch:51, Val Loss: 2.264e+00: 100%|██████████| 17/17 [00:00<00:00, 229.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:52, Train Loss: 2.251e+00: 100%|██████████| 65/65 [00:00<00:00, 165.24it/s]\n",
            "Epoch:52, Val Loss: 2.264e+00: 100%|██████████| 17/17 [00:00<00:00, 336.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:53, Train Loss: 2.249e+00: 100%|██████████| 65/65 [00:00<00:00, 165.60it/s]\n",
            "Epoch:53, Val Loss: 2.264e+00: 100%|██████████| 17/17 [00:00<00:00, 234.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:54, Train Loss: 2.249e+00: 100%|██████████| 65/65 [00:00<00:00, 157.63it/s]\n",
            "Epoch:54, Val Loss: 2.264e+00: 100%|██████████| 17/17 [00:00<00:00, 299.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:55, Train Loss: 2.249e+00: 100%|██████████| 65/65 [00:00<00:00, 150.09it/s]\n",
            "Epoch:55, Val Loss: 2.264e+00: 100%|██████████| 17/17 [00:00<00:00, 297.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:56, Train Loss: 2.250e+00: 100%|██████████| 65/65 [00:00<00:00, 158.88it/s]\n",
            "Epoch:56, Val Loss: 2.265e+00: 100%|██████████| 17/17 [00:00<00:00, 381.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:57, Train Loss: 2.252e+00: 100%|██████████| 65/65 [00:00<00:00, 146.19it/s]\n",
            "Epoch:57, Val Loss: 2.265e+00: 100%|██████████| 17/17 [00:00<00:00, 279.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:58, Train Loss: 2.250e+00: 100%|██████████| 65/65 [00:00<00:00, 149.40it/s]\n",
            "Epoch:58, Val Loss: 2.264e+00: 100%|██████████| 17/17 [00:00<00:00, 271.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:59, Train Loss: 2.248e+00: 100%|██████████| 65/65 [00:00<00:00, 153.18it/s]\n",
            "Epoch:59, Val Loss: 2.264e+00: 100%|██████████| 17/17 [00:00<00:00, 245.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:60, Train Loss: 2.257e+00: 100%|██████████| 65/65 [00:00<00:00, 159.48it/s]\n",
            "Epoch:60, Val Loss: 2.264e+00: 100%|██████████| 17/17 [00:00<00:00, 215.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:61, Train Loss: 2.249e+00: 100%|██████████| 65/65 [00:00<00:00, 154.51it/s]\n",
            "Epoch:61, Val Loss: 2.264e+00: 100%|██████████| 17/17 [00:00<00:00, 224.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:62, Train Loss: 2.250e+00: 100%|██████████| 65/65 [00:00<00:00, 159.09it/s]\n",
            "Epoch:62, Val Loss: 2.264e+00: 100%|██████████| 17/17 [00:00<00:00, 215.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:63, Train Loss: 2.252e+00: 100%|██████████| 65/65 [00:00<00:00, 154.35it/s]\n",
            "Epoch:63, Val Loss: 2.264e+00: 100%|██████████| 17/17 [00:00<00:00, 244.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:64, Train Loss: 2.248e+00: 100%|██████████| 65/65 [00:00<00:00, 153.33it/s]\n",
            "Epoch:64, Val Loss: 2.265e+00: 100%|██████████| 17/17 [00:00<00:00, 208.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:65, Train Loss: 2.256e+00: 100%|██████████| 65/65 [00:00<00:00, 149.12it/s]\n",
            "Epoch:65, Val Loss: 2.265e+00: 100%|██████████| 17/17 [00:00<00:00, 207.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:66, Train Loss: 2.250e+00: 100%|██████████| 65/65 [00:00<00:00, 153.41it/s]\n",
            "Epoch:66, Val Loss: 2.265e+00: 100%|██████████| 17/17 [00:00<00:00, 228.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:67, Train Loss: 2.251e+00: 100%|██████████| 65/65 [00:00<00:00, 151.67it/s]\n",
            "Epoch:67, Val Loss: 2.265e+00: 100%|██████████| 17/17 [00:00<00:00, 211.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:68, Train Loss: 2.252e+00: 100%|██████████| 65/65 [00:00<00:00, 154.95it/s]\n",
            "Epoch:68, Val Loss: 2.265e+00: 100%|██████████| 17/17 [00:00<00:00, 217.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:69, Train Loss: 2.247e+00: 100%|██████████| 65/65 [00:00<00:00, 155.77it/s]\n",
            "Epoch:69, Val Loss: 2.264e+00: 100%|██████████| 17/17 [00:00<00:00, 206.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:70, Train Loss: 2.246e+00: 100%|██████████| 65/65 [00:00<00:00, 149.81it/s]\n",
            "Epoch:70, Val Loss: 2.264e+00: 100%|██████████| 17/17 [00:00<00:00, 217.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:71, Train Loss: 2.245e+00: 100%|██████████| 65/65 [00:00<00:00, 151.64it/s]\n",
            "Epoch:71, Val Loss: 2.265e+00: 100%|██████████| 17/17 [00:00<00:00, 236.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:72, Train Loss: 2.249e+00: 100%|██████████| 65/65 [00:00<00:00, 148.99it/s]\n",
            "Epoch:72, Val Loss: 2.264e+00: 100%|██████████| 17/17 [00:00<00:00, 224.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:73, Train Loss: 2.246e+00: 100%|██████████| 65/65 [00:00<00:00, 155.61it/s]\n",
            "Epoch:73, Val Loss: 2.265e+00: 100%|██████████| 17/17 [00:00<00:00, 245.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:74, Train Loss: 2.250e+00: 100%|██████████| 65/65 [00:00<00:00, 150.80it/s]\n",
            "Epoch:74, Val Loss: 2.265e+00: 100%|██████████| 17/17 [00:00<00:00, 301.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:75, Train Loss: 2.241e+00: 100%|██████████| 65/65 [00:00<00:00, 146.72it/s]\n",
            "Epoch:75, Val Loss: 2.265e+00: 100%|██████████| 17/17 [00:00<00:00, 216.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:76, Train Loss: 2.251e+00: 100%|██████████| 65/65 [00:00<00:00, 153.09it/s]\n",
            "Epoch:76, Val Loss: 2.265e+00: 100%|██████████| 17/17 [00:00<00:00, 211.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:77, Train Loss: 2.246e+00: 100%|██████████| 65/65 [00:00<00:00, 149.60it/s]\n",
            "Epoch:77, Val Loss: 2.265e+00: 100%|██████████| 17/17 [00:00<00:00, 272.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:78, Train Loss: 2.242e+00: 100%|██████████| 65/65 [00:00<00:00, 145.30it/s]\n",
            "Epoch:78, Val Loss: 2.265e+00: 100%|██████████| 17/17 [00:00<00:00, 222.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:79, Train Loss: 2.245e+00: 100%|██████████| 65/65 [00:00<00:00, 147.17it/s]\n",
            "Epoch:79, Val Loss: 2.265e+00: 100%|██████████| 17/17 [00:00<00:00, 249.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:80, Train Loss: 2.245e+00: 100%|██████████| 65/65 [00:00<00:00, 147.18it/s]\n",
            "Epoch:80, Val Loss: 2.265e+00: 100%|██████████| 17/17 [00:00<00:00, 204.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:81, Train Loss: 2.248e+00: 100%|██████████| 65/65 [00:00<00:00, 150.15it/s]\n",
            "Epoch:81, Val Loss: 2.265e+00: 100%|██████████| 17/17 [00:00<00:00, 224.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:82, Train Loss: 2.249e+00: 100%|██████████| 65/65 [00:00<00:00, 150.88it/s]\n",
            "Epoch:82, Val Loss: 2.265e+00: 100%|██████████| 17/17 [00:00<00:00, 215.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:83, Train Loss: 2.242e+00: 100%|██████████| 65/65 [00:00<00:00, 143.94it/s]\n",
            "Epoch:83, Val Loss: 2.265e+00: 100%|██████████| 17/17 [00:00<00:00, 307.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:84, Train Loss: 2.244e+00: 100%|██████████| 65/65 [00:00<00:00, 146.58it/s]\n",
            "Epoch:84, Val Loss: 2.265e+00: 100%|██████████| 17/17 [00:00<00:00, 229.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:85, Train Loss: 2.246e+00: 100%|██████████| 65/65 [00:00<00:00, 157.70it/s]\n",
            "Epoch:85, Val Loss: 2.265e+00: 100%|██████████| 17/17 [00:00<00:00, 225.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:86, Train Loss: 2.241e+00: 100%|██████████| 65/65 [00:00<00:00, 160.96it/s]\n",
            "Epoch:86, Val Loss: 2.265e+00: 100%|██████████| 17/17 [00:00<00:00, 198.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:87, Train Loss: 2.244e+00: 100%|██████████| 65/65 [00:00<00:00, 150.52it/s]\n",
            "Epoch:87, Val Loss: 2.265e+00: 100%|██████████| 17/17 [00:00<00:00, 235.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:88, Train Loss: 2.242e+00: 100%|██████████| 65/65 [00:00<00:00, 164.20it/s]\n",
            "Epoch:88, Val Loss: 2.265e+00: 100%|██████████| 17/17 [00:00<00:00, 228.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:89, Train Loss: 2.245e+00: 100%|██████████| 65/65 [00:00<00:00, 149.40it/s]\n",
            "Epoch:89, Val Loss: 2.265e+00: 100%|██████████| 17/17 [00:00<00:00, 214.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:90, Train Loss: 2.240e+00: 100%|██████████| 65/65 [00:00<00:00, 153.77it/s]\n",
            "Epoch:90, Val Loss: 2.266e+00: 100%|██████████| 17/17 [00:00<00:00, 227.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:91, Train Loss: 2.236e+00: 100%|██████████| 65/65 [00:00<00:00, 153.00it/s]\n",
            "Epoch:91, Val Loss: 2.266e+00: 100%|██████████| 17/17 [00:00<00:00, 205.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:92, Train Loss: 2.247e+00: 100%|██████████| 65/65 [00:00<00:00, 145.91it/s]\n",
            "Epoch:92, Val Loss: 2.266e+00: 100%|██████████| 17/17 [00:00<00:00, 228.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:93, Train Loss: 2.243e+00: 100%|██████████| 65/65 [00:00<00:00, 146.51it/s]\n",
            "Epoch:93, Val Loss: 2.266e+00: 100%|██████████| 17/17 [00:00<00:00, 214.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:94, Train Loss: 2.239e+00: 100%|██████████| 65/65 [00:00<00:00, 155.63it/s]\n",
            "Epoch:94, Val Loss: 2.266e+00: 100%|██████████| 17/17 [00:00<00:00, 386.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:95, Train Loss: 2.242e+00: 100%|██████████| 65/65 [00:00<00:00, 144.31it/s]\n",
            "Epoch:95, Val Loss: 2.266e+00: 100%|██████████| 17/17 [00:00<00:00, 243.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:96, Train Loss: 2.245e+00: 100%|██████████| 65/65 [00:00<00:00, 147.73it/s]\n",
            "Epoch:96, Val Loss: 2.266e+00: 100%|██████████| 17/17 [00:00<00:00, 249.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:97, Train Loss: 2.240e+00: 100%|██████████| 65/65 [00:00<00:00, 143.61it/s]\n",
            "Epoch:97, Val Loss: 2.266e+00: 100%|██████████| 17/17 [00:00<00:00, 303.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:98, Train Loss: 2.240e+00: 100%|██████████| 65/65 [00:00<00:00, 150.18it/s]\n",
            "Epoch:98, Val Loss: 2.266e+00: 100%|██████████| 17/17 [00:00<00:00, 348.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch:99, Train Loss: 2.238e+00: 100%|██████████| 65/65 [00:00<00:00, 140.86it/s]\n",
            "Epoch:99, Val Loss: 2.266e+00: 100%|██████████| 17/17 [00:00<00:00, 304.77it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n",
            "PytorchModel: Metrics on Training Data:\n",
            "accuracy_score = 0.22355769230769232\n",
            "precision_score = 0.020323426573426576\n",
            "recall_score = 0.09090909090909091\n",
            "f1_score = 0.03322021789605287\n",
            "\n",
            "PytorchModel: Metrics on Validation Data:\n",
            "accuracy_score = 0.225\n",
            "precision_score = 0.020454545454545454\n",
            "recall_score = 0.09090909090909091\n",
            "f1_score = 0.03339517625231911\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer based classifier"
      ],
      "metadata": {
        "id": "7zx5ogV9gSul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#split test-train data\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(data['poem'], data['chapter'], test_size=0.20, random_state=2)\n",
        "#x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.1)"
      ],
      "metadata": {
        "id": "sHdfIasbm1-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "install required modules"
      ],
      "metadata": {
        "id": "8ex_jcJxo97g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers"
      ],
      "metadata": {
        "id": "MqHkU8_fo-jK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-processing without tokenizing documents."
      ],
      "metadata": {
        "id": "BrRJqg75ptzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_processed = pre_process(x_train, remove_stopwords=True, MIN_COUNT=0)\n",
        "x_train_processed = [' '.join(x) for x in x_train_processed]\n",
        "\n",
        "x_test_processed = pre_process(x_test, remove_stopwords=True, MIN_COUNT=0)\n",
        "x_test_processed = [' '.join(x) for x in x_test_processed]\n",
        "\n",
        "#x_valid_processed = pre_process(x_valid, remove_stopwords=True, MIN_COUNT=0)\n",
        "#x_valid_processed = [' '.join(x) for x in x_valid_processed]"
      ],
      "metadata": {
        "id": "_J3BFNoQpA9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from transformers import Trainer\n",
        "\n",
        "\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        # forward pass\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.get(\"logits\")\n",
        "        loss_fct = nn.CrossEntropyLoss(weight=torch.tensor(class_weight, dtype=torch.float).to('cuda'))\n",
        "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss"
      ],
      "metadata": {
        "id": "ksdW0nEaJLgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use HooshvareLab(Parsbert) pretrained model to create a new classification model. Use cuda for faster runtime."
      ],
      "metadata": {
        "id": "7cSz3MCvpOXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "import torch\n",
        "\n",
        "MODEL_NAME = 'HooshvareLab/bert-fa-base-uncased'\n",
        "classification_model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=len(data.chapter.value_counts()))\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "classification_model.to(device)"
      ],
      "metadata": {
        "id": "tqiwPb30pCxE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86dd539f-02ea-4ac1-b7e7-923ed638145f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/HooshvareLab/bert-fa-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/58557026b49e9dc674e1f96085a408e0703f4b89cb4470fd9f1ef11ea21c18f9.8188588bbc324b118f288d3ce203479bf1b25266e7ce9fdc628195c43381c732\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"HooshvareLab/bert-fa-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\",\n",
            "    \"5\": \"LABEL_5\",\n",
            "    \"6\": \"LABEL_6\",\n",
            "    \"7\": \"LABEL_7\",\n",
            "    \"8\": \"LABEL_8\",\n",
            "    \"9\": \"LABEL_9\",\n",
            "    \"10\": \"LABEL_10\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_10\": 10,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4,\n",
            "    \"LABEL_5\": 5,\n",
            "    \"LABEL_6\": 6,\n",
            "    \"LABEL_7\": 7,\n",
            "    \"LABEL_8\": 8,\n",
            "    \"LABEL_9\": 9\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.20.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 100000\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/HooshvareLab/bert-fa-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/868db6f52695bdb1f262065ff59a35026b1cdd73dc380b223cf85489f5c02fb3.4441550112f4dc6b4198e0a9b138485892ce5efffd660152e1a2d6a0cb8cec1c\n",
            "Some weights of the model checkpoint at HooshvareLab/bert-fa-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at HooshvareLab/bert-fa-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(100000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=11, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define tokenizer from same pretrained model."
      ],
      "metadata": {
        "id": "kcDb2aVSpoKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
      ],
      "metadata": {
        "id": "SyFtPyQnpPBB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e557bd41-961b-43e4-ba1f-223b43617170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file https://huggingface.co/HooshvareLab/bert-fa-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/58557026b49e9dc674e1f96085a408e0703f4b89cb4470fd9f1ef11ea21c18f9.8188588bbc324b118f288d3ce203479bf1b25266e7ce9fdc628195c43381c732\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"HooshvareLab/bert-fa-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.20.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 100000\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/HooshvareLab/bert-fa-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/d4efb2459ccb463b9dcfb867b20dc784b102fd3c722805993a198bed4113bb2e.be97e2fb95fad2185f02d6ee2f008d628c36bed0cd1b0b8495406c3629e51276\n",
            "loading file https://huggingface.co/HooshvareLab/bert-fa-base-uncased/resolve/main/tokenizer.json from cache at None\n",
            "loading file https://huggingface.co/HooshvareLab/bert-fa-base-uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/HooshvareLab/bert-fa-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/HooshvareLab/bert-fa-base-uncased/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/HooshvareLab/bert-fa-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/58557026b49e9dc674e1f96085a408e0703f4b89cb4470fd9f1ef11ea21c18f9.8188588bbc324b118f288d3ce203479bf1b25266e7ce9fdc628195c43381c732\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"HooshvareLab/bert-fa-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.20.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 100000\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/HooshvareLab/bert-fa-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/58557026b49e9dc674e1f96085a408e0703f4b89cb4470fd9f1ef11ea21c18f9.8188588bbc324b118f288d3ce203479bf1b25266e7ce9fdc628195c43381c732\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"HooshvareLab/bert-fa-base-uncased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.20.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 100000\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating datasets and use tokenizer to decode train, validation, and test data."
      ],
      "metadata": {
        "id": "utLsQuAypjvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "\n",
        "class PoemDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, labels, encoder):\n",
        "        self.encoding = encoder(data, truncation=True, padding=True)\n",
        "        self.labels = labels.to_numpy()\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(value[idx]) for key, value in self.encoding.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = PoemDataset(x_train_processed, y_train, tokenizer)\n",
        "#valid_dataset = PoemDataset(x_valid_processed, y_valid, tokenizer)\n",
        "test_dataset = PoemDataset(x_test_processed, y_test, tokenizer)"
      ],
      "metadata": {
        "id": "fJzAHagSpRAi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b521f509-181a-4523-adae-681e3ea72768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ],
      "metadata": {
        "id": "b61HKmAr-26d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "QD94o4oSFGlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting training arguments for the model. use learning rate 1e-5 to avoid overfitting.\n",
        "\n",
        "Then Train the model."
      ],
      "metadata": {
        "id": "Ea5ASYCLpeX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs = 6,\n",
        "    evaluation_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    warmup_steps=32,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='f1'\n",
        ")\n",
        "\n",
        "trainer = CustomTrainer(\n",
        "    model=classification_model,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "eL_hhxeTpTqx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0af020b1-aafb-45e4-a480-16bc07d68a89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 3251\n",
            "  Num Epochs = 6\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1224\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1224' max='1224' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1224/1224 03:24, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.280200</td>\n",
              "      <td>2.223201</td>\n",
              "      <td>0.157442</td>\n",
              "      <td>0.082341</td>\n",
              "      <td>0.076844</td>\n",
              "      <td>0.132433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.096900</td>\n",
              "      <td>2.151747</td>\n",
              "      <td>0.214022</td>\n",
              "      <td>0.103306</td>\n",
              "      <td>0.092690</td>\n",
              "      <td>0.156377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.978800</td>\n",
              "      <td>2.140031</td>\n",
              "      <td>0.226322</td>\n",
              "      <td>0.122131</td>\n",
              "      <td>0.129495</td>\n",
              "      <td>0.168243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.872300</td>\n",
              "      <td>2.159621</td>\n",
              "      <td>0.253383</td>\n",
              "      <td>0.152920</td>\n",
              "      <td>0.184551</td>\n",
              "      <td>0.189012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.655900</td>\n",
              "      <td>2.200909</td>\n",
              "      <td>0.217712</td>\n",
              "      <td>0.138098</td>\n",
              "      <td>0.151669</td>\n",
              "      <td>0.168629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.599400</td>\n",
              "      <td>2.185274</td>\n",
              "      <td>0.232472</td>\n",
              "      <td>0.157222</td>\n",
              "      <td>0.197545</td>\n",
              "      <td>0.183692</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 813\n",
            "  Batch size = 16\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Saving model checkpoint to ./results/checkpoint-204\n",
            "Configuration saved in ./results/checkpoint-204/config.json\n",
            "Model weights saved in ./results/checkpoint-204/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-204/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-204/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 813\n",
            "  Batch size = 16\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Saving model checkpoint to ./results/checkpoint-408\n",
            "Configuration saved in ./results/checkpoint-408/config.json\n",
            "Model weights saved in ./results/checkpoint-408/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-408/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-408/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 813\n",
            "  Batch size = 16\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Saving model checkpoint to ./results/checkpoint-612\n",
            "Configuration saved in ./results/checkpoint-612/config.json\n",
            "Model weights saved in ./results/checkpoint-612/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-612/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-612/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 813\n",
            "  Batch size = 16\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Saving model checkpoint to ./results/checkpoint-816\n",
            "Configuration saved in ./results/checkpoint-816/config.json\n",
            "Model weights saved in ./results/checkpoint-816/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-816/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-816/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 813\n",
            "  Batch size = 16\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Saving model checkpoint to ./results/checkpoint-1020\n",
            "Configuration saved in ./results/checkpoint-1020/config.json\n",
            "Model weights saved in ./results/checkpoint-1020/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-1020/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-1020/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 813\n",
            "  Batch size = 16\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Saving model checkpoint to ./results/checkpoint-1224\n",
            "Configuration saved in ./results/checkpoint-1224/config.json\n",
            "Model weights saved in ./results/checkpoint-1224/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-1224/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-1224/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./results/checkpoint-1224 (score: 0.15722150016336792).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1224, training_loss=1.9212358784831427, metrics={'train_runtime': 204.6603, 'train_samples_per_second': 95.309, 'train_steps_per_second': 5.981, 'total_flos': 160395592781376.0, 'train_loss': 1.9212358784831427, 'epoch': 6.0})"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs = 6,\n",
        "    evaluation_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    warmup_steps=32,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='f1'\n",
        ")\n",
        "\n",
        "trainer = CustomTrainer(\n",
        "    model=classification_model,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qM5vKqwzaMZX",
        "outputId": "7010cf1d-77a0-4b93-dbde-54bd0cbbde0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 3251\n",
            "  Num Epochs = 6\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1224\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1224' max='1224' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1224/1224 03:20, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.359100</td>\n",
              "      <td>2.280938</td>\n",
              "      <td>0.221402</td>\n",
              "      <td>0.151026</td>\n",
              "      <td>0.212733</td>\n",
              "      <td>0.174074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.091600</td>\n",
              "      <td>2.449702</td>\n",
              "      <td>0.247232</td>\n",
              "      <td>0.195395</td>\n",
              "      <td>0.204150</td>\n",
              "      <td>0.206179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.916400</td>\n",
              "      <td>2.603694</td>\n",
              "      <td>0.253383</td>\n",
              "      <td>0.205210</td>\n",
              "      <td>0.231481</td>\n",
              "      <td>0.208431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.993500</td>\n",
              "      <td>2.754789</td>\n",
              "      <td>0.242312</td>\n",
              "      <td>0.199726</td>\n",
              "      <td>0.206873</td>\n",
              "      <td>0.199824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.677300</td>\n",
              "      <td>2.813376</td>\n",
              "      <td>0.230012</td>\n",
              "      <td>0.198381</td>\n",
              "      <td>0.208053</td>\n",
              "      <td>0.199115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.686400</td>\n",
              "      <td>2.818444</td>\n",
              "      <td>0.234932</td>\n",
              "      <td>0.202941</td>\n",
              "      <td>0.210312</td>\n",
              "      <td>0.202634</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 813\n",
            "  Batch size = 16\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Saving model checkpoint to ./results/checkpoint-204\n",
            "Configuration saved in ./results/checkpoint-204/config.json\n",
            "Model weights saved in ./results/checkpoint-204/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-204/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-204/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 813\n",
            "  Batch size = 16\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Saving model checkpoint to ./results/checkpoint-408\n",
            "Configuration saved in ./results/checkpoint-408/config.json\n",
            "Model weights saved in ./results/checkpoint-408/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-408/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-408/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 813\n",
            "  Batch size = 16\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Saving model checkpoint to ./results/checkpoint-612\n",
            "Configuration saved in ./results/checkpoint-612/config.json\n",
            "Model weights saved in ./results/checkpoint-612/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-612/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-612/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 813\n",
            "  Batch size = 16\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Saving model checkpoint to ./results/checkpoint-816\n",
            "Configuration saved in ./results/checkpoint-816/config.json\n",
            "Model weights saved in ./results/checkpoint-816/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-816/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-816/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 813\n",
            "  Batch size = 16\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Saving model checkpoint to ./results/checkpoint-1020\n",
            "Configuration saved in ./results/checkpoint-1020/config.json\n",
            "Model weights saved in ./results/checkpoint-1020/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-1020/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-1020/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 813\n",
            "  Batch size = 16\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Saving model checkpoint to ./results/checkpoint-1224\n",
            "Configuration saved in ./results/checkpoint-1224/config.json\n",
            "Model weights saved in ./results/checkpoint-1224/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-1224/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-1224/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./results/checkpoint-612 (score: 0.2052099806937191).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1224, training_loss=0.9264850661255954, metrics={'train_runtime': 201.1416, 'train_samples_per_second': 96.976, 'train_steps_per_second': 6.085, 'total_flos': 160395592781376.0, 'train_loss': 0.9264850661255954, 'epoch': 6.0})"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs = 6,\n",
        "    evaluation_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    warmup_steps=32,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='f1'\n",
        ")\n",
        "\n",
        "trainer = CustomTrainer(\n",
        "    model=classification_model,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iOufEESJcMZC",
        "outputId": "ba116844-8477-41ab-b416-1bfc7cea87cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 3251\n",
            "  Num Epochs = 6\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1224\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1224' max='1224' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1224/1224 03:19, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.477500</td>\n",
              "      <td>2.880664</td>\n",
              "      <td>0.237392</td>\n",
              "      <td>0.194874</td>\n",
              "      <td>0.299030</td>\n",
              "      <td>0.193206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.338900</td>\n",
              "      <td>3.007650</td>\n",
              "      <td>0.238622</td>\n",
              "      <td>0.212259</td>\n",
              "      <td>0.252080</td>\n",
              "      <td>0.218344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.346800</td>\n",
              "      <td>3.371300</td>\n",
              "      <td>0.239852</td>\n",
              "      <td>0.206581</td>\n",
              "      <td>0.258301</td>\n",
              "      <td>0.203840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>3.425286</td>\n",
              "      <td>0.233702</td>\n",
              "      <td>0.208395</td>\n",
              "      <td>0.242662</td>\n",
              "      <td>0.211880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.313200</td>\n",
              "      <td>3.471857</td>\n",
              "      <td>0.231242</td>\n",
              "      <td>0.201589</td>\n",
              "      <td>0.234741</td>\n",
              "      <td>0.203553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.301800</td>\n",
              "      <td>3.458084</td>\n",
              "      <td>0.234932</td>\n",
              "      <td>0.208479</td>\n",
              "      <td>0.234084</td>\n",
              "      <td>0.206933</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 813\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-204\n",
            "Configuration saved in ./results/checkpoint-204/config.json\n",
            "Model weights saved in ./results/checkpoint-204/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-204/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-204/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 813\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-408\n",
            "Configuration saved in ./results/checkpoint-408/config.json\n",
            "Model weights saved in ./results/checkpoint-408/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-408/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-408/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 813\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-612\n",
            "Configuration saved in ./results/checkpoint-612/config.json\n",
            "Model weights saved in ./results/checkpoint-612/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-612/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-612/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 813\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-816\n",
            "Configuration saved in ./results/checkpoint-816/config.json\n",
            "Model weights saved in ./results/checkpoint-816/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-816/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-816/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 813\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-1020\n",
            "Configuration saved in ./results/checkpoint-1020/config.json\n",
            "Model weights saved in ./results/checkpoint-1020/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-1020/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-1020/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 813\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-1224\n",
            "Configuration saved in ./results/checkpoint-1224/config.json\n",
            "Model weights saved in ./results/checkpoint-1224/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-1224/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-1224/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./results/checkpoint-408 (score: 0.21225878877389573).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1224, training_loss=0.34638017191995985, metrics={'train_runtime': 199.9395, 'train_samples_per_second': 97.56, 'train_steps_per_second': 6.122, 'total_flos': 160395592781376.0, 'train_loss': 0.34638017191995985, 'epoch': 6.0})"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "predict test data and evaluate the model and plot confusion matrix:"
      ],
      "metadata": {
        "id": "JVoSOanQpb02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = trainer.predict(test_dataset)\n",
        "pred_y = pred.predictions.argmax(-1)"
      ],
      "metadata": {
        "id": "tFbzusbUpV0L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "cdd3dd8e-531f-4d3e-da7d-eaaaf216f835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 813\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [51/51 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_metrics_evaluation(y_test, pred_y, 'Transformer Based')\n",
        "plot_confusion_matrix(y_test, pred_y)"
      ],
      "metadata": {
        "id": "Bs2MkgcCpWcx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "72de0689-b7eb-4cf5-dee1-4f2649af839d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transformer Based:\n",
            "accuracy_score = 0.23862238622386223\n",
            "precision_score = 0.25207985308204073\n",
            "recall_score = 0.2183442700227179\n",
            "f1_score = 0.21225878877389573\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phase 3: Link Anylysis"
      ],
      "metadata": {
        "id": "PG7VS8fKb1f8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data = pd.concat([boostan_data, golestan_data], ignore_index=True).drop(columns = ['section', 'chapter'])\n",
        "# it seems to work better on boostan only\n",
        "data = boostan_data.drop(columns = ['section', 'chapter'])\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "iOPA_w2dc3kg",
        "outputId": "566b8fa0-7f2a-4aa5-9218-edeb3f16357e"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                poem\n",
              "0   به نام خداوندِ جان‌آفرین\\nحکیمِ سخن‌درزبان‌آفرین\n",
              "1       خداوند بخشندهٔ دستگیر\\nکریم خطابخش پوزش‌پذیر\n",
              "2  عزیزی که هر کز درش سر بتافت\\nبه هر در که شد هی...\n",
              "3    سر پادشاهان گردن‌فراز\\nبه درگاه او بر زمین نیاز\n",
              "4  نه گردن‌کشان را بگیرد به فور\\nنه عذرآوران را ب..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d942dd4f-1e85-4d3e-97e6-ec5d5b15fdb2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>poem</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>به نام خداوندِ جان‌آفرین\\nحکیمِ سخن‌درزبان‌آفرین</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>خداوند بخشندهٔ دستگیر\\nکریم خطابخش پوزش‌پذیر</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>عزیزی که هر کز درش سر بتافت\\nبه هر در که شد هی...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>سر پادشاهان گردن‌فراز\\nبه درگاه او بر زمین نیاز</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>نه گردن‌کشان را بگیرد به فور\\nنه عذرآوران را ب...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d942dd4f-1e85-4d3e-97e6-ec5d5b15fdb2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d942dd4f-1e85-4d3e-97e6-ec5d5b15fdb2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d942dd4f-1e85-4d3e-97e6-ec5d5b15fdb2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(analyzer= lambda x: sent_pre_process(x, remove_stopwords=True))\n",
        "tfidf_data = tfidf.fit_transform(data.poem.to_numpy())\n",
        "tfidf_data = tfidf_data.toarray()\n",
        "tfidf_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c7ad0c7-209c-4794-a6d0-72f62ef59ae8",
        "id": "shvxPVl7c3k4"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4064, 6893)"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_matrix = np.matmul(tfidf_data, tfidf_data.T)\n",
        "similarity_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEyno-I_e4Dg",
        "outputId": "bf4fc54f-f83e-44d9-9273-f42cbf2a38d7"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4064, 4064)"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.3\n",
        "\n",
        "adj_matrix = (similarity_matrix > threshold).astype(int)\n",
        "# do we need this?\n",
        "adj_matrix -= np.eye(len(adj_matrix), dtype=int)\n",
        "print(f'Number of links: {adj_matrix.sum()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N10y-vMNe4Bx",
        "outputId": "5ff7ed77-2085-4649-f9a3-e2abb8fd7c53"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of links: 4366\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "adj_graph = nx.from_numpy_array(adj_matrix)\n",
        "probabilities = nx.pagerank(adj_graph)"
      ],
      "metadata": {
        "id": "e_ph2Iw-ggnO"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_idx = sorted(probabilities, key=probabilities.get, reverse=True)\n",
        "probabilities[max_idx[0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1W0PcN1thWEr",
        "outputId": "132164be-e04d-45d6-915b-c98c184b30dc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.003827895757140323"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for poem in data.poem[max_idx[0: 5]]:\n",
        "    print(poem)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOmy4-yFiTJS",
        "outputId": "4a4481fd-8690-40ed-f520-d7bffc8ac6e2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "به نرمی ز دشمن توان کرد دوست\n",
            "چو با دوست سختی کنی دشمن اوست\n",
            "\n",
            "که چشم از تو دارند مردم بسی\n",
            "نه تو چشم داری به دست کسی\n",
            "\n",
            "به روی من این در کسی کرد باز\n",
            "که کردی تو بر روی وی در، فراز\n",
            "\n",
            "یکی فتنه دید از طرف بر شکست\n",
            "یکی در میان آمد و سر شکست\n",
            "\n",
            "اگر هست مرد از هنر بهره‌ور\n",
            "هنر خود بگوید نه صاحب هنر\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div dir='rtl'> \n",
        "<font face=\"B Nazanin\">\n",
        "\n",
        "تحلیل خروجی:\n",
        "<br/>\n",
        "ابتدا با ضرب ماتریس tfidfها در یک دیگر و به دست آوردن\n",
        "ضرب داخلی سطرهای مختلف در هم، بر اساس بزرگ‌تر یا کوچک‌تر بودن شباهت نسبت به ترشهولد، ماتریس مجاورت را ایجاد کردیم.\n",
        "<br/>\n",
        "برای انتخاب ترشهولد مناسب، آن را به گونه‌ای تغییر دادیم که تعداد لینک‌هایی که بین ابیات مختلف وجود دارد، از اردر تعداد ابیات بوستان باشد.\n",
        "در این صورت نه تعداد لینک‌ها بسیار زیاد است که احتمال‌ها خیلی نزدیک به یکدیگر شود و نه آن قدر کم است که امکان جابجا شدن از برخی ابیات وجود نداشته باشد.\n",
        "<br/>\n",
        "شعری که بیشترین احتمال را در الگوریتم\n",
        "pagerank\n",
        "دریافت می‌کند بیت \n",
        "«به نرمی ز دشمن توان کرد دوست / چو با دوست سختی کنی دشمن اوست»\n",
        "است که یکی از پرتکرارترین مضامین موجود در بوستان سعدی است. که مضمون اصلی آن این است در هر کاری محبت و دوستی بسیار کارسازتر است از جنگ و دشمنی. و انسان خوب نباید حتی در برخورد با انسان‌های بد و دشمنانش نیز راه و رسم خود را کنار بگذارد و به بدی روی بیاورد. و با این کار حتی ممکن است دشمنان نیز دست از بدی کردن بکشند.\n",
        "<br/>\n",
        "با کمی جستجو در بوستان ابیات مشابه زیادی همچون این بیت می‌توانیم بیابیم:\n",
        "<br/>\n",
        "«همی تا برآید به تدبیر کار / مدارای دشمن به از کارزار»\n",
        "<br/>\n",
        "«چو کاری براید به لطف و خوشی / چه حاجت به تندی و گردنکشی»\n",
        "<br/>\n",
        "«گرت طبع من آمد ناسزاوار / تو خوی نیک خویش از دست مگذار»\n",
        "<br/>\n",
        "حتی در سعدی ابیات دیگری نیز دارد که در آن‌ها بیان می‌کند لطف و خشم هر یک به جای خود مناسب هستند و یا ابیاتی که بیان می‌کند باید با بدان به مانند خودشان بد بود (اغلب علت این ابیاتی که ممکن است جداگانه متناقض به نظر برسند این است که معمولا در یک حکایت افراد مختلف نظرات مختلفی درباره‌ی این موضوع بیان کرده‌اند). که این گونه ابیات نیز ارتباط تنگاتنگی با ابیات بالا دارند و با آن‌ها لینک می‌شوند. مانند ابیات زیر:\n",
        "<br/>\n",
        "«هر که را دشمن پیش است گر دکشد دشمن خویش است»\n",
        "<br/>\n",
        "«چو با سفله گویی به لطف و خوشی / فزون گرددش کبر و گردن کشی»\n",
        "<br/>\n",
        "«بگفتا نیک‌مردی کن نه چندان / که گردد خیره گرگ تیزدندان»\n",
        "<br/>\n",
        "«ترحم بر پلنگ تیزدندان / سمتمکاری بود بر گوسپندان»\n",
        "<br/>\n",
        "«درشتی و نرمی به‌هم‌در به است / جو رگ‌زن که جراح و مرهم‌نه است»\n",
        "<br/>\n",
        "«مبخشای بر هر کجا ظالمی‌ست / که رحمت بر او جور بر عالمی‌ست»\n",
        "<br/>\n",
        "«هر آن کس که بر دزد رحمت کند / به بازوی خود کاروان می‌زند»\n",
        "<br/>\n",
        "«جفاپیشگان را بده سر به باد / ستم بر ستم‌پیشه عدل است و داد»\n",
        "<br/>\n",
        "پس طبیعی است که این مضامین مرتبط و پرتکرار، ابیاتشان با هم لینک شود و \n",
        "random walker\n",
        "ما با احتمال بیشتری در یکی از آن‌ها قرار بگیرد.\n",
        "\n",
        "</div>"
      ],
      "metadata": {
        "id": "KM6wp2WQpv4S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use NetworkX HTIS algorithm to estimate hubs and authority of nodes."
      ],
      "metadata": {
        "id": "zli75FmXGfeQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hubs, authority = nx.hits(adj_graph)"
      ],
      "metadata": {
        "id": "4suAB14tvOcD"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we sort nodes based on their hubs and then print the 5 nodes with the most hubs."
      ],
      "metadata": {
        "id": "bR01HiogG6Ub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Based on hubs\n",
        "\n",
        "max_idx = list(sorted(hubs, key=hubs.get, reverse=True))\n",
        "hubs[max_idx[0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a2BQLaJLxUd",
        "outputId": "39283dd7-4afe-484a-9840-5b62a7198839"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08391799304174069"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for poem in data.poem[max_idx[0:5]]:\n",
        "    print(poem)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wa6DeF6HN42",
        "outputId": "138cf45d-66ea-48a3-9cb9-02c3433c441b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "به نرمی ز دشمن توان کرد دوست\n",
            "چو با دوست سختی کنی دشمن اوست\n",
            "\n",
            "بود دشمنش تازه و دوست ریش\n",
            "کسی کش بود دشمن از دوست بیش\n",
            "\n",
            "چو دشمن به دشمن بود مشتغل\n",
            "تو با دوست بنشین به آرام دل\n",
            "\n",
            "بر این گفتم آن دوست دشمن گرفت\n",
            "چو آتش شد از خشم و در من گرفت\n",
            "\n",
            "مگر پیش دشمن بگویند و دوست\n",
            "که این کشته دست و شمشیر اوست\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we do the same thing based on authority to check if results are diffrent."
      ],
      "metadata": {
        "id": "WGn9O2-GJsSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Based on authority\n",
        "\n",
        "max_idx = list(sorted(authority, key=authority.get, reverse=True))\n",
        "authority[max_idx[0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgG5bp0LFSoA",
        "outputId": "3b02df86-3a40-4437-a943-a7d4962995f3"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08391799304174068"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for poem in data.poem[max_idx[0:5]]:\n",
        "    print(poem)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsqhxXxEFkUH",
        "outputId": "ca0cee8e-e7be-4f9f-ccfd-0ccde16a4f03"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "به نرمی ز دشمن توان کرد دوست\n",
            "چو با دوست سختی کنی دشمن اوست\n",
            "\n",
            "بود دشمنش تازه و دوست ریش\n",
            "کسی کش بود دشمن از دوست بیش\n",
            "\n",
            "چو دشمن به دشمن بود مشتغل\n",
            "تو با دوست بنشین به آرام دل\n",
            "\n",
            "بر این گفتم آن دوست دشمن گرفت\n",
            "چو آتش شد از خشم و در من گرفت\n",
            "\n",
            "مگر پیش دشمن بگویند و دوست\n",
            "که این کشته دست و شمشیر اوست\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<div dir=rtl>\n",
        "<font face=\"B Nazanin\">\n",
        "\n",
        "همانطور که میتوانسیتم انتظار آن را داشته باشیم نتایج حاصل شده توسط \n",
        "authority و hubs\n",
        "با یکدیگر تفاوت ندارند چرا که گراف ساخته شده براساس شباهت‌ها دو طرفه است و به عبارتی ماتریس مجاورت آن متقارن می‌باشد. همینطور می‌توانیم ببینیم که در اینجا هم بیتی که بیشترین ارزش را دارد همان بیت «به نرم ز دشمن توان کرد دوست، چو با دوست سختی کنی دشمن اوست» می‌باشد. که در این‌جا به این معنیست که بیشترین مقدار یال‌ها به این راس می‌رسد و به نظر می‌رسد که مفهوم محبت و دوستی در ابیات سعدی بسیار به چشم می‌خورد و برجسته است.\n",
        "\n",
        "</div>"
      ],
      "metadata": {
        "id": "dv8I4-XqN3n0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer based"
      ],
      "metadata": {
        "id": "inL59X1FSzKI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using our phase one transformer model we create embedded vector of every poems."
      ],
      "metadata": {
        "id": "M5q7dnZwViMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_model = my_transformer(boostan_data['poem'])\n",
        "transformer_vector = transformer_model.vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Htc82bcGLL-L",
        "outputId": "648074e4-3c8d-44c3-ee77-923cc110867c"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at HooshvareLab/bert-fa-zwnj-base were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertModel were not initialized from the model checkpoint at HooshvareLab/bert-fa-zwnj-base and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we normalize vectors and create similarity matrix and after that do the same process as tf-idf vectors."
      ],
      "metadata": {
        "id": "u46IzaeTV_zF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(transformer_vector)):\n",
        "    transformer_vector[i] = transformer_vector[i] / np.linalg.norm(transformer_vector[i]) "
      ],
      "metadata": {
        "id": "ubUUXukCPkP-"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_matrix_transformer = np.matmul(transformer_vector, transformer_vector.T)\n",
        "similarity_matrix_transformer.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rIJZt-TM5gD",
        "outputId": "bbb8d9a4-4fba-4016-a20c-d9cfddcfb4ed"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4064, 4064)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.69\n",
        "\n",
        "adj_matrix_transformer = (similarity_matrix_transformer > threshold).astype(int)\n",
        "# do we need this?\n",
        "adj_matrix_transformer -= np.eye(len(adj_matrix_transformer), dtype=int)\n",
        "print(f'Number of links: {adj_matrix_transformer.sum()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQX9NY8HOnGa",
        "outputId": "ca4f08c7-c43e-46be-cf3f-825272799555"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of links: 355270\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "adj_graph_transformer = nx.from_numpy_array(adj_matrix_transformer)\n",
        "probabilities = nx.pagerank(adj_graph_transformer)"
      ],
      "metadata": {
        "id": "h_AruMBoQYjl"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_idx = sorted(probabilities, key=probabilities.get, reverse=True)\n",
        "probabilities[max_idx[0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcn6afWMQaho",
        "outputId": "9389ec13-a42c-4428-bda7-0bd1bc66af01"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.002116671097428274"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for poem in data.poem[max_idx[0:5]]:\n",
        "    print(poem)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFqGiJBdQyuu",
        "outputId": "7f2f69ab-3e34-4fe0-885b-363702bb0cbf"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "زبان آمد از بهر شکر و سپاس\n",
            "به غیبت نگرداندش حق شناس\n",
            "\n",
            "زبان در نهندش به ایذا چو تیغ\n",
            "که بدبخت زر دارد از خود دریغ\n",
            "\n",
            "یکی شکر گفت اندران خاک و دود\n",
            "که دکان ما را گزندی نبود\n",
            "\n",
            "نیوشنده شد زین سخن تنگدل\n",
            "به فکرت فرو رفت چون خر به گل\n",
            "\n",
            "به پای بت اندر به امید خیر\n",
            "بغلطید بیچاره بر خاک دیر\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hubs, authority = nx.hits(adj_graph_transformer)"
      ],
      "metadata": {
        "id": "jqg6p1lMUOPl"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_idx = list(sorted(hubs, key=hubs.get, reverse=True))\n",
        "hubs[max_idx[0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJP_GxbCUPDs",
        "outputId": "32721749-4086-41db-a35c-c705b09aa435"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0023943399138527713"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for poem in data.poem[max_idx[0:5]]:\n",
        "    print(poem)\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjPwmdubUPJP",
        "outputId": "2990d99c-1bd5-4586-bd90-15f812ad15dd"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "به پای بت اندر به امید خیر\n",
            "بغلطید بیچاره بر خاک دیر\n",
            "\n",
            "یکی شکر گفت اندران خاک و دود\n",
            "که دکان ما را گزندی نبود\n",
            "\n",
            "زبان آمد از بهر شکر و سپاس\n",
            "به غیبت نگرداندش حق شناس\n",
            "\n",
            "زبان در نهندش به ایذا چو تیغ\n",
            "که بدبخت زر دارد از خود دریغ\n",
            "\n",
            "نیوشنده شد زین سخن تنگدل\n",
            "به فکرت فرو رفت چون خر به گل\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<div dir=rtl>\n",
        "<font face=\"B Nazanin\">\n",
        "\n",
        "نتایج حاصل شده از روش HITS \n",
        "و \n",
        "PageRank\n",
        "تفاوت چندانی با یکدیگر ندارند و می‌توانیم ببینیم که در روش PageRank\n",
        "مفهوم «غیبت نکردن» را مفهموم برجسته‌ای در نظر گرفته است. که البته می‌توان دید که با ابیات دیگری که به ارزش زیادی برای آن تشخیص داده است شباهت زیادی نداشته است. در کل روش tf-idf\n",
        "روش موثرتری برای ساختن ماتریس شباهت‌ها به نظر می‌آید. \n",
        "\n",
        "</div>"
      ],
      "metadata": {
        "id": "_GHCu35uYEUK"
      }
    }
  ]
}